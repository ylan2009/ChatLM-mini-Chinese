#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®å¤„ç†ç®¡é“è¯Šæ–­è„šæœ¬
ç”¨äºæ£€æŸ¥æ•°æ®å¤„ç†æµç¨‹ä¸­æ¯ä¸€æ­¥çš„æ•°æ®è´¨é‡ï¼Œæ‰¾å‡º prompt ä¸ºç©ºçš„é—®é¢˜å‡ºç°åœ¨å“ªä¸€æ­¥
"""

import sys
sys.path.extend(['.', '..'])

from fastparquet import ParquetFile
import pandas as pd
from pathlib import Path
import argparse
from collections import defaultdict
from config import PROJECT_ROOT


class DataQualityChecker:
    """æ•°æ®è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.file_name = Path(file_path).name
        self.stats = {
            'total_rows': 0,
            'empty_prompt': 0,
            'empty_response': 0,
            'both_empty': 0,
            'valid': 0,
            'none_prompt': 0,
            'none_response': 0,
            'whitespace_only_prompt': 0,
            'whitespace_only_response': 0,
        }
        self.samples = {
            'empty_prompt': [],
            'empty_response': [],
            'valid': [],
        }
        self.prompt_lengths = []
        self.response_lengths = []
    
    def check_parquet(self, max_samples=5, show_progress=True):
        """æ£€æŸ¥ parquet æ–‡ä»¶"""
        print(f"\n{'='*100}")
        print(f"ğŸ“ æ£€æŸ¥æ–‡ä»¶: {self.file_path}")
        print(f"{'='*100}\n")
        
        try:
            pf = ParquetFile(self.file_path)
            
            if show_progress:
                print("ğŸ” å¼€å§‹æ‰«ææ•°æ®...")
            
            # é€å—è¯»å–æ•°æ®
            for chunk in pf:
                for rows in chunk.iter_row_groups():
                    # å°è¯•ä¸åŒçš„åˆ—å
                    prompts = None
                    responses = None
                    
                    # æ£€æŸ¥å¯èƒ½çš„åˆ—å
                    columns = rows.columns.tolist()
                    
                    # æŸ¥æ‰¾ prompt åˆ—
                    for col in ['prompt', 'instruction', 'input', 'question']:
                        if col in columns:
                            prompts = rows[col].tolist()
                            break
                    
                    # æŸ¥æ‰¾ response åˆ—
                    for col in ['response', 'output', 'answer', 'target']:
                        if col in columns:
                            responses = rows[col].tolist()
                            break
                    
                    if prompts is None or responses is None:
                        print(f"âš ï¸  è­¦å‘Š: æ— æ³•æ‰¾åˆ° prompt/response åˆ—")
                        print(f"   å¯ç”¨åˆ—: {columns}")
                        return None
                    
                    # åˆ†ææ¯ä¸€è¡Œ
                    for prompt, response in zip(prompts, responses):
                        self.stats['total_rows'] += 1
                        
                        # æ£€æŸ¥ None å€¼
                        if prompt is None:
                            self.stats['none_prompt'] += 1
                            prompt = ""
                        if response is None:
                            self.stats['none_response'] += 1
                            response = ""
                        
                        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        prompt_str = str(prompt)
                        response_str = str(response)
                        
                        # æ£€æŸ¥ç©ºå­—ç¬¦ä¸²
                        prompt_len = len(prompt_str)
                        response_len = len(response_str)
                        
                        prompt_stripped_len = len(prompt_str.strip())
                        response_stripped_len = len(response_str.strip())
                        
                        self.prompt_lengths.append(prompt_stripped_len)
                        self.response_lengths.append(response_stripped_len)
                        
                        # ç»Ÿè®¡å„ç§æƒ…å†µ
                        if prompt_stripped_len == 0:
                            self.stats['empty_prompt'] += 1
                            if prompt_len > 0:
                                self.stats['whitespace_only_prompt'] += 1
                            
                            if len(self.samples['empty_prompt']) < max_samples:
                                self.samples['empty_prompt'].append({
                                    'row': self.stats['total_rows'],
                                    'prompt': repr(prompt_str[:100]),
                                    'response': response_str[:100],
                                    'prompt_is_none': prompt is None,
                                })
                        
                        if response_stripped_len == 0:
                            self.stats['empty_response'] += 1
                            if response_len > 0:
                                self.stats['whitespace_only_response'] += 1
                            
                            if len(self.samples['empty_response']) < max_samples:
                                self.samples['empty_response'].append({
                                    'row': self.stats['total_rows'],
                                    'prompt': prompt_str[:100],
                                    'response': repr(response_str[:100]),
                                    'response_is_none': response is None,
                                })
                        
                        if prompt_stripped_len == 0 and response_stripped_len == 0:
                            self.stats['both_empty'] += 1
                        
                        if prompt_stripped_len > 0 and response_stripped_len > 0:
                            self.stats['valid'] += 1
                            if len(self.samples['valid']) < max_samples:
                                self.samples['valid'].append({
                                    'row': self.stats['total_rows'],
                                    'prompt': prompt_str[:100],
                                    'response': response_str[:100],
                                })
                        
                        # æ˜¾ç¤ºè¿›åº¦
                        if show_progress and self.stats['total_rows'] % 100000 == 0:
                            print(f"   å·²å¤„ç† {self.stats['total_rows']:,} è¡Œ...")
            
            if show_progress:
                print(f"âœ… æ‰«æå®Œæˆï¼å…±å¤„ç† {self.stats['total_rows']:,} è¡Œ\n")
            
            return self.stats
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def print_report(self):
        """æ‰“å°æ£€æŸ¥æŠ¥å‘Š"""
        total = self.stats['total_rows']
        if total == 0:
            print("âš ï¸  æ²¡æœ‰æ•°æ®")
            return
        
        print(f"{'='*100}")
        print(f"ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š: {self.file_name}")
        print(f"{'='*100}\n")
        
        # åŸºæœ¬ç»Ÿè®¡
        print("ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
        print(f"  æ€»è¡Œæ•°: {total:,}")
        print(f"  æœ‰æ•ˆæ•°æ® (prompt å’Œ response éƒ½ä¸ä¸ºç©º): {self.stats['valid']:,} ({self.stats['valid']/total*100:.2f}%)")
        print()
        
        # ç©ºå€¼ç»Ÿè®¡
        print("ğŸ” ç©ºå€¼ç»Ÿè®¡:")
        print(f"  ç©º prompt: {self.stats['empty_prompt']:,} ({self.stats['empty_prompt']/total*100:.2f}%)")
        print(f"    - None å€¼: {self.stats['none_prompt']:,}")
        print(f"    - ä»…ç©ºç™½å­—ç¬¦: {self.stats['whitespace_only_prompt']:,}")
        print(f"  ç©º response: {self.stats['empty_response']:,} ({self.stats['empty_response']/total*100:.2f}%)")
        print(f"    - None å€¼: {self.stats['none_response']:,}")
        print(f"    - ä»…ç©ºç™½å­—ç¬¦: {self.stats['whitespace_only_response']:,}")
        print(f"  ä¸¤è€…éƒ½ä¸ºç©º: {self.stats['both_empty']:,} ({self.stats['both_empty']/total*100:.2f}%)")
        print()
        
        # é•¿åº¦ç»Ÿè®¡
        if self.prompt_lengths:
            print("ğŸ“ Prompt é•¿åº¦ç»Ÿè®¡:")
            print(f"  å¹³å‡é•¿åº¦: {sum(self.prompt_lengths)/len(self.prompt_lengths):.2f}")
            print(f"  æœ€å°é•¿åº¦: {min(self.prompt_lengths)}")
            print(f"  æœ€å¤§é•¿åº¦: {max(self.prompt_lengths)}")
            print()
        
        if self.response_lengths:
            print("ğŸ“ Response é•¿åº¦ç»Ÿè®¡:")
            print(f"  å¹³å‡é•¿åº¦: {sum(self.response_lengths)/len(self.response_lengths):.2f}")
            print(f"  æœ€å°é•¿åº¦: {min(self.response_lengths)}")
            print(f"  æœ€å¤§é•¿åº¦: {max(self.response_lengths)}")
            print()
        
        # æ•°æ®è´¨é‡è¯„çº§
        valid_rate = self.stats['valid'] / total * 100
        print("â­ æ•°æ®è´¨é‡è¯„çº§:")
        if valid_rate >= 95:
            print(f"  âœ… ä¼˜ç§€ ({valid_rate:.2f}% æœ‰æ•ˆæ•°æ®)")
        elif valid_rate >= 80:
            print(f"  âš ï¸  è‰¯å¥½ ({valid_rate:.2f}% æœ‰æ•ˆæ•°æ®)")
        elif valid_rate >= 50:
            print(f"  âš ï¸  ä¸€èˆ¬ ({valid_rate:.2f}% æœ‰æ•ˆæ•°æ®)")
        else:
            print(f"  âŒ è¾ƒå·® ({valid_rate:.2f}% æœ‰æ•ˆæ•°æ®)")
        print()
        
        # æ˜¾ç¤ºæ ·ä¾‹
        if self.samples['empty_prompt']:
            print(f"{'='*100}")
            print(f"ğŸ” ç©º Prompt æ ·ä¾‹ (å‰ {len(self.samples['empty_prompt'])} æ¡):")
            print(f"{'='*100}")
            for sample in self.samples['empty_prompt']:
                print(f"\nç¬¬ {sample['row']} è¡Œ:")
                print(f"  Prompt (is_none={sample.get('prompt_is_none', False)}): {sample['prompt']}")
                print(f"  Response: {sample['response']}")
        
        if self.samples['valid']:
            print(f"\n{'='*100}")
            print(f"âœ… æœ‰æ•ˆæ•°æ®æ ·ä¾‹ (å‰ {len(self.samples['valid'])} æ¡):")
            print(f"{'='*100}")
            for sample in self.samples['valid']:
                print(f"\nç¬¬ {sample['row']} è¡Œ:")
                print(f"  Prompt: {sample['prompt']}")
                print(f"  Response: {sample['response']}")
        
        print(f"\n{'='*100}\n")


def check_single_file(file_path: str, max_samples=5):
    """æ£€æŸ¥å•ä¸ªæ–‡ä»¶"""
    if not Path(file_path).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    
    checker = DataQualityChecker(file_path)
    checker.check_parquet(max_samples=max_samples)
    checker.print_report()
    
    return checker.stats


def check_pipeline(data_dir: str = None):
    """æ£€æŸ¥æ•´ä¸ªæ•°æ®å¤„ç†ç®¡é“"""
    if data_dir is None:
        data_dir = PROJECT_ROOT + '/data'
    
    print(f"\n{'#'*100}")
    print(f"# æ•°æ®å¤„ç†ç®¡é“è¯Šæ–­")
    print(f"# æ•°æ®ç›®å½•: {data_dir}")
    print(f"{'#'*100}\n")
    
    # å®šä¹‰æ•°æ®å¤„ç†æµç¨‹ä¸­çš„å…³é”®æ–‡ä»¶
    pipeline_files = [
        {
            'name': 'åŸå§‹ Belle æ•°æ®',
            'path': f'{data_dir}/raw_data/belle/Belle_open_source_0.5M.parquet',
            'description': 'ä» Hugging Face ä¸‹è½½çš„åŸå§‹æ•°æ®'
        },
        {
            'name': 'å»é‡åçš„æ•°æ®',
            'path': f'{data_dir}/my_dataset_no_dulpticates.parquet',
            'description': 'remove_dataset_duplicate_rows å¤„ç†åçš„æ•°æ®'
        },
        {
            'name': 'å¤„ç†åçš„å¾®è°ƒæ•°æ®',
            'path': f'{data_dir}/my_finetune_data_zh.parquet',
            'description': 'process_belle_knowledge_enhanced_dataset_for_finetune å¤„ç†åçš„æ•°æ®'
        },
        {
            'name': 'Shuffle åçš„æ•°æ®',
            'path': f'{data_dir}/my_finetune_data_zh_shuffled.parquet',
            'description': 'shuffle_parquet_dataset å¤„ç†åçš„æ•°æ®'
        },
    ]
    
    # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶
    results = {}
    for file_info in pipeline_files:
        file_path = file_info['path']
        
        print(f"\n{'='*100}")
        print(f"ğŸ” æ­¥éª¤: {file_info['name']}")
        print(f"ğŸ“ è¯´æ˜: {file_info['description']}")
        print(f"{'='*100}")
        
        if not Path(file_path).exists():
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}\n")
            results[file_info['name']] = None
            continue
        
        checker = DataQualityChecker(file_path)
        stats = checker.check_parquet(max_samples=3, show_progress=True)
        
        if stats:
            checker.print_report()
            results[file_info['name']] = stats
        else:
            results[file_info['name']] = None
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print(f"\n{'#'*100}")
    print(f"# ç®¡é“å¯¹æ¯”æŠ¥å‘Š")
    print(f"{'#'*100}\n")
    
    print(f"{'æ­¥éª¤':<30} {'æ€»è¡Œæ•°':>15} {'æœ‰æ•ˆæ•°æ®':>15} {'ç©ºPrompt':>15} {'ç©ºResponse':>15}")
    print(f"{'-'*100}")
    
    for file_info in pipeline_files:
        name = file_info['name']
        stats = results.get(name)
        
        if stats is None:
            print(f"{name:<30} {'N/A':>15} {'N/A':>15} {'N/A':>15} {'N/A':>15}")
        else:
            total = stats['total_rows']
            valid = stats['valid']
            empty_prompt = stats['empty_prompt']
            empty_response = stats['empty_response']
            
            valid_pct = f"{valid:,} ({valid/total*100:.1f}%)" if total > 0 else "0"
            empty_p_pct = f"{empty_prompt:,} ({empty_prompt/total*100:.1f}%)" if total > 0 else "0"
            empty_r_pct = f"{empty_response:,} ({empty_response/total*100:.1f}%)" if total > 0 else "0"
            
            print(f"{name:<30} {total:>15,} {valid_pct:>15} {empty_p_pct:>15} {empty_r_pct:>15}")
    
    print(f"\n{'#'*100}\n")
    
    # åˆ†æé—®é¢˜
    print("ğŸ” é—®é¢˜åˆ†æ:\n")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶çš„ç©º prompt æ¯”ä¾‹çªç„¶å¢åŠ 
    prev_empty_rate = 0
    problem_found = False
    
    for file_info in pipeline_files:
        name = file_info['name']
        stats = results.get(name)
        
        if stats and stats['total_rows'] > 0:
            empty_rate = stats['empty_prompt'] / stats['total_rows'] * 100
            
            if empty_rate > 50:
                print(f"âŒ ä¸¥é‡é—®é¢˜: '{name}' ä¸­æœ‰ {empty_rate:.1f}% çš„æ•°æ® prompt ä¸ºç©ºï¼")
                print(f"   æ–‡ä»¶è·¯å¾„: {file_info['path']}")
                print(f"   è¿™ä¸€æ­¥å¯èƒ½å­˜åœ¨é—®é¢˜ï¼\n")
                problem_found = True
            elif empty_rate > prev_empty_rate + 10:
                print(f"âš ï¸  è­¦å‘Š: '{name}' ä¸­ç©º prompt æ¯”ä¾‹å¢åŠ äº† {empty_rate - prev_empty_rate:.1f}%")
                print(f"   ä» {prev_empty_rate:.1f}% å¢åŠ åˆ° {empty_rate:.1f}%")
                print(f"   æ–‡ä»¶è·¯å¾„: {file_info['path']}")
                print(f"   è¿™ä¸€æ­¥å¯èƒ½å¼•å…¥äº†é—®é¢˜ï¼\n")
                problem_found = True
            
            prev_empty_rate = empty_rate
    
    if not problem_found:
        print("âœ… æœªå‘ç°æ˜æ˜¾çš„æ•°æ®è´¨é‡é—®é¢˜")
    
    print(f"\n{'#'*100}\n")


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®å¤„ç†ç®¡é“è¯Šæ–­å·¥å…·')
    parser.add_argument('--file', type=str, help='æ£€æŸ¥å•ä¸ªæ–‡ä»¶')
    parser.add_argument('--pipeline', action='store_true', help='æ£€æŸ¥æ•´ä¸ªæ•°æ®å¤„ç†ç®¡é“')
    parser.add_argument('--data-dir', type=str, help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--samples', type=int, default=5, help='æ˜¾ç¤ºçš„æ ·ä¾‹æ•°é‡')
    
    args = parser.parse_args()
    
    if args.file:
        # æ£€æŸ¥å•ä¸ªæ–‡ä»¶
        check_single_file(args.file, max_samples=args.samples)
    elif args.pipeline:
        # æ£€æŸ¥æ•´ä¸ªç®¡é“
        check_pipeline(data_dir=args.data_dir)
    else:
        # é»˜è®¤æ£€æŸ¥æ•´ä¸ªç®¡é“
        print("æœªæŒ‡å®šå‚æ•°ï¼Œé»˜è®¤æ£€æŸ¥æ•´ä¸ªæ•°æ®å¤„ç†ç®¡é“")
        print("ä½¿ç”¨ --file <æ–‡ä»¶è·¯å¾„> æ£€æŸ¥å•ä¸ªæ–‡ä»¶")
        print("ä½¿ç”¨ --pipeline æ£€æŸ¥æ•´ä¸ªç®¡é“\n")
        check_pipeline(data_dir=args.data_dir)


if __name__ == '__main__':
    main()
