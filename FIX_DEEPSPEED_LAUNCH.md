# ğŸš¨ DeepSpeed å¯åŠ¨é”™è¯¯ä¿®å¤

## âŒ é”™è¯¯ä¿¡æ¯

```bash
deepspeed: error: unrecognized arguments: -m
```

---

## ğŸ” é—®é¢˜åˆ†æ

### é”™è¯¯åŸå› 

**deepspeed å’Œ torchrun ä¸æ”¯æŒ `-m` å‚æ•°ï¼**

| å¯åŠ¨å™¨ | æ”¯æŒ `-m` | æ­£ç¡®ç”¨æ³• |
|--------|----------|---------|
| `python` | âœ… | `python -m llmtuner.cli` |
| `accelerate launch` | âœ… | `accelerate launch -m llmtuner.cli` |
| `deepspeed` | âŒ | `deepspeed script.py` |
| `torchrun` | âŒ | `torchrun script.py` |

### åŸå› è¯´æ˜

- `python -m module` æ˜¯ Python çš„æ¨¡å—è¿è¡Œæ–¹å¼
- `deepspeed` å’Œ `torchrun` æ˜¯**å¯åŠ¨å™¨**ï¼Œä¸æ˜¯ Python è§£é‡Šå™¨
- å®ƒä»¬éœ€è¦**ç›´æ¥çš„ Python è„šæœ¬è·¯å¾„**ï¼Œè€Œä¸æ˜¯æ¨¡å—å

---

## âœ… è§£å†³æ–¹æ¡ˆ

### ğŸ¯ æ–¹æ¡ˆ1: ä½¿ç”¨ llamafactory-cliï¼ˆæ¨èï¼‰â­â­â­

**æœ€ç®€å•çš„æ–¹å¼ï¼š**

```bash
# ç›´æ¥ä½¿ç”¨ llamafactory-cli
llamafactory-cli train llamafactory_config_3x3080.yaml
```

**ä¼˜ç‚¹ï¼š**
- âœ… è‡ªåŠ¨å¤„ç† DeepSpeed é…ç½®
- âœ… ä¸éœ€è¦å…³å¿ƒè„šæœ¬è·¯å¾„
- âœ… æœ€ç®€å•ï¼Œæœ€ä¸å®¹æ˜“å‡ºé”™

---

### ğŸ¯ æ–¹æ¡ˆ2: æ‰¾åˆ°è„šæœ¬è·¯å¾„å¹¶ä½¿ç”¨ deepspeed

**æ­£ç¡®çš„ deepspeed å¯åŠ¨æ–¹å¼ï¼š**

```bash
# 1. æ‰¾åˆ° llmtuner çš„ cli.py è·¯å¾„
LLMTUNER_CLI=$(python -c "import llmtuner; import os; print(os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py'))")

# 2. ä½¿ç”¨ deepspeed å¯åŠ¨ï¼ˆä¸è¦ç”¨ -mï¼‰
deepspeed \
    --num_gpus=3 \
    --master_port=29500 \
    "$LLMTUNER_CLI" train llamafactory_config_3x3080.yaml
```

**æ³¨æ„ï¼š**
- âŒ é”™è¯¯ï¼š`deepspeed -m llmtuner.cli`
- âœ… æ­£ç¡®ï¼š`deepspeed /path/to/cli.py`

---

### ğŸ¯ æ–¹æ¡ˆ3: ä½¿ç”¨ accelerate launchï¼ˆæ”¯æŒ -mï¼‰

**accelerate æ”¯æŒ `-m` å‚æ•°ï¼š**

```bash
accelerate launch \
    --multi_gpu \
    --num_processes=3 \
    --main_process_port=29500 \
    -m llmtuner.cli train llamafactory_config_3x3080.yaml
```

---

### ğŸ¯ æ–¹æ¡ˆ4: ä½¿ç”¨ torchrunï¼ˆéœ€è¦è„šæœ¬è·¯å¾„ï¼‰

**æ­£ç¡®çš„ torchrun å¯åŠ¨æ–¹å¼ï¼š**

```bash
# 1. æ‰¾åˆ°è„šæœ¬è·¯å¾„
LLMTUNER_CLI=$(python -c "import llmtuner; import os; print(os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py'))")

# 2. ä½¿ç”¨ torchrun å¯åŠ¨ï¼ˆä¸è¦ç”¨ -mï¼‰
torchrun \
    --nproc_per_node=3 \
    --master_port=29500 \
    "$LLMTUNER_CLI" train llamafactory_config_3x3080.yaml
```

---

## ğŸ”§ å·²ä¿®å¤çš„å¯åŠ¨è„šæœ¬

æˆ‘å·²ç»ä¿®å¤äº† `run_llamafactory_3x3080.sh`ï¼Œç°åœ¨å¯ä»¥æ­£ç¡®ä½¿ç”¨æ‰€æœ‰å¯åŠ¨æ–¹å¼ï¼š

### ä¿®å¤å†…å®¹

#### 1. DeepSpeed å¯åŠ¨ï¼ˆæ–¹å¼3ï¼‰

```bash
# ä¿®å¤å‰ï¼ˆé”™è¯¯ï¼‰
deepspeed --num_gpus=3 -m llmtuner.cli train config.yaml

# ä¿®å¤åï¼ˆæ­£ç¡®ï¼‰
LLMTUNER_CLI=$(python -c "import llmtuner; import os; print(os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py'))")
deepspeed --num_gpus=3 "$LLMTUNER_CLI" train config.yaml
```

#### 2. Torchrun å¯åŠ¨ï¼ˆæ–¹å¼4ï¼‰

```bash
# ä¿®å¤å‰ï¼ˆé”™è¯¯ï¼‰
torchrun --nproc_per_node=3 -m llmtuner.cli train config.yaml

# ä¿®å¤åï¼ˆæ­£ç¡®ï¼‰
LLMTUNER_CLI=$(python -c "import llmtuner; import os; print(os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py'))")
torchrun --nproc_per_node=3 "$LLMTUNER_CLI" train config.yaml
```

#### 3. ç¯å¢ƒå˜é‡ä¿®å¤

```bash
# ä¿®å¤å‰ï¼ˆå·²å¼ƒç”¨ï¼‰
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# ä¿®å¤åï¼ˆæ–°ç‰ˆæœ¬ï¼‰
export PYTORCH_ALLOC_CONF=max_split_size_mb:128
```

---

## ğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œäº†

### Step 1: é‡æ–°è¿è¡Œå¯åŠ¨è„šæœ¬

```bash
cd /data3/ChatLM-mini-Chinese
bash run_llamafactory_3x3080.sh
```

### Step 2: é€‰æ‹©è®­ç»ƒæ–¹å¼

```
è¯·é€‰æ‹©è®­ç»ƒæ–¹å¼:
  1) ä½¿ç”¨ llamafactory-cli (æ¨èï¼Œæœ€ç®€å•)
  2) ä½¿ç”¨ accelerate launch (æ›´çµæ´»)
  3) ä½¿ç”¨ deepspeed (æœ€ä¼˜æ˜¾å­˜åˆ©ç”¨)      â† ç°åœ¨å¯ä»¥æ­£å¸¸å·¥ä½œäº†ï¼
  4) ä½¿ç”¨ torchrun (æ ‡å‡†DDP)            â† ç°åœ¨å¯ä»¥æ­£å¸¸å·¥ä½œäº†ï¼

è¯·è¾“å…¥é€‰é¡¹ [1-4]: 3
```

### Step 3: å¼€å§‹è®­ç»ƒ

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. âœ… æ‰¾åˆ°æ­£ç¡®çš„è„šæœ¬è·¯å¾„
2. âœ… ä½¿ç”¨æ­£ç¡®çš„å¯åŠ¨å‘½ä»¤
3. âœ… å¼€å§‹è®­ç»ƒ

---

## ğŸ“Š å„ç§å¯åŠ¨æ–¹å¼å¯¹æ¯”

| å¯åŠ¨æ–¹å¼ | å‘½ä»¤æ ¼å¼ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨èåº¦ |
|---------|---------|------|------|--------|
| **llamafactory-cli** | `llamafactory-cli train config.yaml` | æœ€ç®€å•ï¼Œè‡ªåŠ¨å¤„ç†ä¸€åˆ‡ | çµæ´»æ€§è¾ƒä½ | â­â­â­â­â­ |
| **accelerate** | `accelerate launch -m llmtuner.cli` | çµæ´»ï¼Œæ”¯æŒå¤šç§é…ç½® | éœ€è¦é…ç½® | â­â­â­â­ |
| **deepspeed** | `deepspeed script.py` | æœ€ä¼˜æ˜¾å­˜åˆ©ç”¨ | éœ€è¦è„šæœ¬è·¯å¾„ | â­â­â­â­ |
| **torchrun** | `torchrun script.py` | æ ‡å‡†DDP | éœ€è¦è„šæœ¬è·¯å¾„ | â­â­â­ |

---

## ğŸ’¡ ä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™ä¸ªé—®é¢˜ï¼Ÿ

### åŸå› 1: æ··æ·†äº† Python å’Œå¯åŠ¨å™¨

```bash
# Python è§£é‡Šå™¨ï¼ˆæ”¯æŒ -mï¼‰
python -m module_name  # âœ… æ­£ç¡®

# å¯åŠ¨å™¨ï¼ˆä¸æ”¯æŒ -mï¼‰
deepspeed -m module_name  # âŒ é”™è¯¯
torchrun -m module_name   # âŒ é”™è¯¯
```

### åŸå› 2: æ–‡æ¡£ç¤ºä¾‹ä¸ç»Ÿä¸€

ä¸åŒçš„æ–‡æ¡£å¯èƒ½ä½¿ç”¨ä¸åŒçš„å¯åŠ¨æ–¹å¼ï¼Œå®¹æ˜“æ··æ·†ï¼š

```bash
# æœ‰äº›æ–‡æ¡£è¿™æ ·å†™ï¼ˆé€‚ç”¨äº accelerateï¼‰
accelerate launch -m llmtuner.cli

# æœ‰äº›æ–‡æ¡£è¿™æ ·å†™ï¼ˆé€‚ç”¨äº deepspeedï¼‰
deepspeed /path/to/script.py

# å¯¼è‡´ç”¨æˆ·æ··æ·†
```

---

## ğŸ”’ é˜²æ­¢å†æ¬¡å‡ºç°

### æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨ llamafactory-cli

```bash
# æœ€ç®€å•ï¼Œä¸ä¼šå‡ºé”™
llamafactory-cli train config.yaml
```

### æ–¹æ³•2: è®°ä½å¯åŠ¨å™¨çš„ç‰¹æ€§

| å¯åŠ¨å™¨ | æ”¯æŒ `-m` | éœ€è¦è„šæœ¬è·¯å¾„ |
|--------|----------|-------------|
| `python` | âœ… | âŒ |
| `accelerate launch` | âœ… | âŒ |
| `deepspeed` | âŒ | âœ… |
| `torchrun` | âŒ | âœ… |

### æ–¹æ³•3: ä½¿ç”¨å°è£…è„šæœ¬

ä½¿ç”¨ `run_llamafactory_3x3080.sh`ï¼Œå®ƒå·²ç»å¤„ç†äº†æ‰€æœ‰ç»†èŠ‚ã€‚

---

## ğŸ“ å¿«é€Ÿå‚è€ƒ

### æ‰¾åˆ° llmtuner è„šæœ¬è·¯å¾„

```bash
python -c "import llmtuner; import os; print(os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py'))"
```

### æ­£ç¡®çš„å¯åŠ¨å‘½ä»¤

```bash
# æ–¹å¼1: llamafactory-cliï¼ˆæ¨èï¼‰
llamafactory-cli train config.yaml

# æ–¹å¼2: accelerateï¼ˆæ”¯æŒ -mï¼‰
accelerate launch -m llmtuner.cli train config.yaml

# æ–¹å¼3: deepspeedï¼ˆéœ€è¦è„šæœ¬è·¯å¾„ï¼‰
SCRIPT=$(python -c "import llmtuner; import os; print(os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py'))")
deepspeed --num_gpus=3 "$SCRIPT" train config.yaml

# æ–¹å¼4: torchrunï¼ˆéœ€è¦è„šæœ¬è·¯å¾„ï¼‰
SCRIPT=$(python -c "import llmtuner; import os; print(os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py'))")
torchrun --nproc_per_node=3 "$SCRIPT" train config.yaml
```

---

## ğŸ¯ æ€»ç»“

**é—®é¢˜ï¼š** deepspeed ä¸æ”¯æŒ `-m` å‚æ•°

**è§£å†³æ–¹æ¡ˆï¼š**
1. ä½¿ç”¨ `llamafactory-cli`ï¼ˆæœ€ç®€å•ï¼‰
2. æˆ–è€…æ‰¾åˆ°è„šæœ¬è·¯å¾„ï¼Œä½¿ç”¨ `deepspeed script.py`

**æ‰§è¡Œå‘½ä»¤ï¼š**
```bash
cd /data3/ChatLM-mini-Chinese
bash run_llamafactory_3x3080.sh
# é€‰æ‹©æ–¹å¼ 3ï¼ˆdeepspeedï¼‰
```

**ç°åœ¨åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œäº†ï¼** ğŸ‰

---

## ğŸ“ è¿˜æœ‰é—®é¢˜ï¼Ÿ

å¦‚æœè¿˜æœ‰é”™è¯¯ï¼Œè¯·æä¾›ï¼š
1. å®Œæ•´çš„é”™è¯¯ä¿¡æ¯
2. ä½¿ç”¨çš„å¯åŠ¨æ–¹å¼ï¼ˆ1-4ï¼‰
3. Python å’Œ PyTorch ç‰ˆæœ¬

```bash
# æ”¶é›†è¯Šæ–­ä¿¡æ¯
python -c "
import sys
import torch
import transformers
import llmtuner
import os

print('Python:', sys.version)
print('PyTorch:', torch.__version__)
print('transformers:', transformers.__version__)
print('CUDA:', torch.version.cuda)
print()
print('llmtuner è·¯å¾„:', llmtuner.__file__)
print('cli.py è·¯å¾„:', os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py'))
print('cli.py å­˜åœ¨:', os.path.exists(os.path.join(os.path.dirname(llmtuner.__file__), 'cli.py')))
"
```
