# SFTè®­ç»ƒé…ç½®å¯¹æ¯”è¯´æ˜

## ğŸ“Š ä¸‰ç§é…ç½®å¯¹æ¯”

### 1. TrainConfigSFTSmallï¼ˆä½å†…å­˜æ¨¡å¼ï¼‰
**é€‚ç”¨åœºæ™¯**ï¼šå†…å­˜ç´§å¼ ï¼ˆ<10GBå¯ç”¨ï¼‰

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| batch_size_per_gpu | 1 | æè‡´ä½å†…å­˜ |
| gradient_accumulation_steps | 8 | é€šè¿‡æ¢¯åº¦ç´¯ç§¯è¡¥å¿å°batch |
| å®é™…æœ‰æ•ˆbatch_size | 16 | 1 Ã— 2(GPU) Ã— 8 |
| GPUæ˜¾å­˜å ç”¨ | 2-3GB/GPU | æ˜¾å­˜åˆ©ç”¨ç‡ä½ |
| å†…å­˜å ç”¨ | 6-8GB | é€‚åˆ16GBå†…å­˜ |
| è®­ç»ƒé€Ÿåº¦ | åŸºå‡†é€Ÿåº¦ | è¾ƒæ…¢ |

**å¯åŠ¨å‘½ä»¤**ï¼š
```bash
./quick_start_sft_gloo.sh
# æˆ–
accelerate launch --multi_gpu --num_processes 2 \
    ./train_low_mem.py train \
    --is_finetune=True \
    --use_small_config=True
```

---

### 2. TrainConfigSFTFastï¼ˆé«˜æ€§èƒ½æ¨¡å¼ï¼‰â­ æ¨è
**é€‚ç”¨åœºæ™¯**ï¼šGPUæ˜¾å­˜å……è¶³ï¼ˆ20GBï¼‰ï¼Œå†…å­˜å¯ç”¨ï¼ˆ>7GBï¼‰

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| batch_size_per_gpu | 8 | å……åˆ†åˆ©ç”¨GPUæ˜¾å­˜ |
| gradient_accumulation_steps | 2 | å‡å°‘å†…å­˜å ç”¨ |
| å®é™…æœ‰æ•ˆbatch_size | 32 | 8 Ã— 2(GPU) Ã— 2 |
| GPUæ˜¾å­˜å ç”¨ | 8-12GB/GPU | æ˜¾å­˜åˆ©ç”¨ç‡æå‡4-5å€ |
| å†…å­˜å ç”¨ | 8-12GB | é€‚åˆ16GBå†…å­˜ |
| è®­ç»ƒé€Ÿåº¦ | **3-4å€** | å¤§å¹…æå‡ |

**å¯åŠ¨å‘½ä»¤**ï¼š
```bash
./quick_start_sft_fast.sh
# æˆ–
accelerate launch --multi_gpu --num_processes 2 \
    ./train_low_mem.py train \
    --is_finetune=True \
    --use_fast_config=True
```

---

### 3. TrainConfigSFTï¼ˆæ ‡å‡†æ¨¡å¼ï¼‰
**é€‚ç”¨åœºæ™¯**ï¼šå¤§æ•°æ®é›†ï¼ˆ>10kæ ·æœ¬ï¼‰ï¼Œå†…å­˜å……è¶³ï¼ˆ>20GBï¼‰

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| batch_size_per_gpu | 20 | æ ‡å‡†é…ç½® |
| gradient_accumulation_steps | 6 | å¹³è¡¡æ€§èƒ½ |
| å®é™…æœ‰æ•ˆbatch_size | 240 | 20 Ã— 2(GPU) Ã— 6 |
| GPUæ˜¾å­˜å ç”¨ | 15-18GB/GPU | æ¥è¿‘æ˜¾å­˜ä¸Šé™ |
| å†…å­˜å ç”¨ | 15-20GB | éœ€è¦æ›´å¤§å†…å­˜ |
| è®­ç»ƒé€Ÿåº¦ | æœ€å¿« | ä½†éœ€è¦æ›´å¤šèµ„æº |

**å¯åŠ¨å‘½ä»¤**ï¼š
```bash
accelerate launch --multi_gpu --num_processes 2 \
    ./train_low_mem.py train \
    --is_finetune=True
```

---

## ğŸ¯ å¦‚ä½•é€‰æ‹©é…ç½®ï¼Ÿ

### æ ¹æ®ä½ çš„ç¡¬ä»¶æƒ…å†µï¼š
- **GPUæ˜¾å­˜**: 20GB Ã— 2 âœ…
- **å†…å­˜**: 16GBï¼ˆå¯ç”¨7GBï¼‰âœ…
- **æ•°æ®é›†**: 5,000æ ·æœ¬ï¼ˆå°æ•°æ®é›†ï¼‰

### æ¨èæ–¹æ¡ˆï¼š
**ä½¿ç”¨ TrainConfigSFTFastï¼ˆé«˜æ€§èƒ½æ¨¡å¼ï¼‰**

**ç†ç”±**ï¼š
1. âœ… GPUæ˜¾å­˜å……è¶³ï¼ˆ20GBï¼‰ï¼Œç›®å‰åªç”¨äº†2.5GBï¼ˆ12.5%ï¼‰ï¼Œæµªè´¹ä¸¥é‡
2. âœ… å†…å­˜å¯ç”¨7GBï¼Œè¶³å¤Ÿæ”¯æŒbatch_size=8
3. âœ… å°æ•°æ®é›†ä¸éœ€è¦è¶…å¤§batch_sizeï¼Œ32å·²ç»è¶³å¤Ÿ
4. âœ… è®­ç»ƒé€Ÿåº¦æå‡3-4å€ï¼Œå¤§å¹…ç¼©çŸ­è®­ç»ƒæ—¶é—´

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”ï¼ˆ5000æ ·æœ¬ï¼Œ3ä¸ªepochï¼‰

| é…ç½® | æ¯epochæ­¥æ•° | å•epochæ—¶é•¿ | æ€»è®­ç»ƒæ—¶é•¿ | GPUåˆ©ç”¨ç‡ |
|------|------------|------------|-----------|----------|
| Small | 312æ­¥ | ~2å°æ—¶ | ~6å°æ—¶ | 12% |
| **Fast** | **156æ­¥** | **~30åˆ†é’Ÿ** | **~1.5å°æ—¶** | **50-60%** |
| Standard | 21æ­¥ | ~10åˆ†é’Ÿ | ~30åˆ†é’Ÿ | 90% |

**æ³¨æ„**ï¼šStandardæ¨¡å¼è™½ç„¶æœ€å¿«ï¼Œä½†éœ€è¦æ›´å¤§å†…å­˜ï¼ˆ>20GBï¼‰ï¼Œä½ çš„16GBå†…å­˜å¯èƒ½ä¸å¤Ÿã€‚

---

## ğŸš€ ç«‹å³å¼€å§‹

### æ–¹æ³•1ï¼šä½¿ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
```bash
cd /data3/ChatLM-mini-Chinese
chmod +x quick_start_sft_fast.sh
./quick_start_sft_fast.sh
```

### æ–¹æ³•2ï¼šæ‰‹åŠ¨å¯åŠ¨
```bash
cd /data3/ChatLM-mini-Chinese
export ACCELERATE_USE_GLOO=1

accelerate launch --multi_gpu --num_processes 2 \
    ./train_low_mem.py train \
    --is_finetune=True \
    --use_fast_config=True
```

---

## ğŸ”§ è¿›ä¸€æ­¥ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

å¦‚æœè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç°ï¼š

### 1. å†…å­˜è¿˜æœ‰ä½™é‡ï¼ˆ>3GBå¯ç”¨ï¼‰
å¯ä»¥å°è¯•è¿›ä¸€æ­¥å¢å¤§batch_sizeï¼š
```bash
accelerate launch --multi_gpu --num_processes 2 \
    ./train_low_mem.py train \
    --is_finetune=True \
    --use_fast_config=True \
    --batch_size_per_gpu=12
```

### 2. GPUæ˜¾å­˜è¿˜æœ‰ä½™é‡ï¼ˆ>8GBå¯ç”¨ï¼‰
å¯ä»¥å°è¯•æ›´å¤§çš„batch_sizeï¼š
```bash
accelerate launch --multi_gpu --num_processes 2 \
    ./train_low_mem.py train \
    --is_finetune=True \
    --use_fast_config=True \
    --batch_size_per_gpu=16
```

### 3. å†…å­˜ä¸å¤Ÿï¼ˆOOMï¼‰
é™ä½batch_sizeï¼š
```bash
accelerate launch --multi_gpu --num_processes 2 \
    ./train_low_mem.py train \
    --is_finetune=True \
    --use_fast_config=True \
    --batch_size_per_gpu=4
```

---

## ğŸ“ ç›‘æ§è®­ç»ƒ

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç›‘æ§èµ„æºä½¿ç”¨ï¼š

```bash
# ç›‘æ§GPU
watch -n 1 nvidia-smi

# ç›‘æ§å†…å­˜
watch -n 1 free -h

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/chat_trainer_*.log
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **é¦–æ¬¡ä½¿ç”¨Fastæ¨¡å¼**ï¼šå»ºè®®å…ˆè¿è¡Œ1ä¸ªepochï¼Œè§‚å¯Ÿå†…å­˜å’ŒGPUæ˜¾å­˜å ç”¨
2. **å¦‚æœå‡ºç°OOM**ï¼šé™ä½batch_size_per_gpuï¼ˆä»8é™åˆ°4æˆ–6ï¼‰
3. **è®­ç»ƒç¨³å®šå**ï¼šå¯ä»¥å°è¯•è¿›ä¸€æ­¥å¢å¤§batch_sizeä»¥æå‡é€Ÿåº¦
4. **ä¿å­˜ä½ç½®**ï¼šæ¨¡å‹ä¿å­˜åœ¨ `./model_save/sft_fast/`

---

## ğŸ‰ é¢„æœŸæ•ˆæœ

ä½¿ç”¨ **TrainConfigSFTFast** åï¼š
- âœ… GPUæ˜¾å­˜åˆ©ç”¨ç‡ï¼šä»12% â†’ 50-60%ï¼ˆæå‡4-5å€ï¼‰
- âœ… è®­ç»ƒé€Ÿåº¦ï¼šä»6å°æ—¶ â†’ 1.5å°æ—¶ï¼ˆæå‡4å€ï¼‰
- âœ… å†…å­˜å ç”¨ï¼šä¿æŒåœ¨10GBå·¦å³ï¼ˆå®‰å…¨èŒƒå›´ï¼‰
- âœ… è®­ç»ƒæ•ˆæœï¼šä¸Smallæ¨¡å¼ç›¸åŒï¼ˆæœ‰æ•ˆbatch_sizeæ›´å¤§ï¼Œå¯èƒ½æ›´å¥½ï¼‰
