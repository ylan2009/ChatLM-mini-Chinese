# 16Gå†…å­˜SFTè®­ç»ƒå®Œæ•´æ–¹æ¡ˆ

## ğŸ“‹ é—®é¢˜åˆ†æ

ä½ çš„ç¯å¢ƒï¼š
- **æ€»å†…å­˜**ï¼š16GB
- **å¯ç”¨å†…å­˜**ï¼š13GB+
- **ç›®æ ‡**ï¼šä»å¤§æ•°æ®é›†ä¸­é€‰æ‹©åˆé€‚æ•°é‡çš„æ•°æ®è¿›è¡ŒSFTè®­ç»ƒ
- **æ•°æ®æº**ï¼š`my_finetune_data_zh.parquet` æˆ– `sft_train.json`

## âœ… è§£å†³æ–¹æ¡ˆ

æˆ‘å·²ç»ä¸ºä½ å‡†å¤‡äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

### 1. æ•°æ®é‡‡æ ·å·¥å…· - [`prepare_small_sft_data.py`](prepare_small_sft_data.py)

**åŠŸèƒ½**ï¼š
- âœ… æ”¯æŒä» `.parquet` æˆ– `.json` æ–‡ä»¶é‡‡æ ·
- âœ… è‡ªåŠ¨åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
- âœ… è‡ªåŠ¨ä¼°ç®—å†…å­˜ä½¿ç”¨é‡
- âœ… ç»™å‡ºè®­ç»ƒå»ºè®®

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
# ä»parquetæ–‡ä»¶é‡‡æ ·5000ä¸ªæ ·æœ¬ï¼ˆæ¨èï¼‰
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_5k.parquet \
    --num_samples 5000 \
    --valid_ratio 0.1

# ä»jsonæ–‡ä»¶é‡‡æ ·
python prepare_small_sft_data.py \
    --input data/alpaca_gpt4_data_zh.json \
    --output data/sft_5k.parquet \
    --num_samples 5000
```

### 2. ä¼˜åŒ–é…ç½®ç±» - [`config.py`](config.py)

æ–°å¢ `TrainConfigSFTSmall` é…ç½®ç±»ï¼Œä¸“é—¨é’ˆå¯¹16Gå†…å­˜ä¼˜åŒ–ï¼š

```python
class TrainConfigSFTSmall:
    epochs: int = 3                    # å°æ•°æ®é›†3ä¸ªepoch
    batch_size_per_gpu: int = 1        # æè‡´ä½å†…å­˜
    gradient_accumulation_steps: int = 8  # æ¢¯åº¦ç´¯ç§¯è¡¥å¿
    
    # æ•°æ®æ–‡ä»¶ï¼ˆä½¿ç”¨é‡‡æ ·åçš„å°æ•°æ®é›†ï¼‰
    train_file = './data/sft_5k_train.parquet'
    validation_file = './data/sft_5k_valid.parquet'
```

### 3. ä¸€é”®å¯åŠ¨è„šæœ¬ - [`quick_start_sft_small.sh`](quick_start_sft_small.sh)

**æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼**ï¼š
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆ5000æ ·æœ¬ï¼‰
./quick_start_sft_small.sh

# è‡ªå®šä¹‰æ ·æœ¬æ•°
./quick_start_sft_small.sh --samples 3000

# ä»JSONæ–‡ä»¶é‡‡æ ·
./quick_start_sft_small.sh --input data/alpaca_gpt4_data_zh.json --samples 5000
```

è„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆï¼š
1. âœ… æ•°æ®é‡‡æ ·
2. âœ… æ›´æ–°é…ç½®æ–‡ä»¶
3. âœ… å¯åŠ¨è®­ç»ƒ

### 4. è¯¦ç»†æŒ‡å— - [`SFT_SMALL_DATASET_GUIDE.md`](SFT_SMALL_DATASET_GUIDE.md)

åŒ…å«ï¼š
- å†…å­˜ä¸æ•°æ®é‡å¯¹åº”å…³ç³»
- è¯¦ç»†ä½¿ç”¨æ­¥éª¤
- é«˜çº§ä¼˜åŒ–é€‰é¡¹
- å¸¸è§é—®é¢˜è§£ç­”

## ğŸ¯ æ¨èé…ç½®ï¼ˆ16Gå†…å­˜ï¼‰

æ ¹æ®ä½ çš„å†…å­˜é™åˆ¶ï¼Œæˆ‘æ¨èï¼š

| é…ç½®é¡¹ | æ¨èå€¼ | è¯´æ˜ |
|-------|--------|------|
| **è®­ç»ƒæ ·æœ¬æ•°** | **5,000** | å¹³è¡¡æ•ˆæœä¸å†…å­˜ |
| **éªŒè¯æ ·æœ¬æ•°** | **500** | 10%éªŒè¯é›† |
| **Batch size** | **1** | æ¯GPU |
| **æ¢¯åº¦ç´¯ç§¯** | **8** | æœ‰æ•ˆbatch=16 |
| **Epochs** | **3** | é¿å…è¿‡æ‹Ÿåˆ |
| **é¢„æœŸå†…å­˜** | **8-10GB** | åŒGPUæ€»è®¡ |
| **è®­ç»ƒæ—¶é•¿** | **2-4å°æ—¶/epoch** | å–å†³äºGPU |

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3æ­¥ï¼‰

### æ–¹å¼Aï¼šä½¿ç”¨ä¸€é”®è„šæœ¬ï¼ˆæœ€ç®€å•ï¼‰

```bash
# 1. ç»™è„šæœ¬æ‰§è¡Œæƒé™ï¼ˆé¦–æ¬¡éœ€è¦ï¼‰
chmod +x quick_start_sft_small.sh

# 2. è¿è¡Œè„šæœ¬
./quick_start_sft_small.sh

# å°±è¿™ä¹ˆç®€å•ï¼è„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆæ‰€æœ‰æ­¥éª¤
```

### æ–¹å¼Bï¼šæ‰‹åŠ¨æ‰§è¡Œï¼ˆæ›´çµæ´»ï¼‰

```bash
# 1. å‡†å¤‡æ•°æ®ï¼ˆ5000æ ·æœ¬ï¼‰
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_5k.parquet \
    --num_samples 5000

# 2. ä¿®æ”¹ config.py
# å°† TrainConfigSFTSmall ä¸­çš„æ–‡ä»¶è·¯å¾„æ”¹ä¸ºï¼š
#   train_file = PROJECT_ROOT + '/data/sft_5k_train.parquet'
#   validation_file = PROJECT_ROOT + '/data/sft_5k_valid.parquet'

# 3. å¼€å§‹è®­ç»ƒ
accelerate launch --multi_gpu --num_processes 2 ./train_low_mem.py train --is_finetune=True
```

## ğŸ“Š ä¸åŒæ ·æœ¬æ•°çš„é€‰æ‹©

| æ ·æœ¬æ•° | å†…å­˜å ç”¨ | è®­ç»ƒæ—¶é•¿ | é€‚ç”¨åœºæ™¯ |
|-------|---------|---------|---------|
| 3,000 | ~6-8GB | 1-2h/epoch | å¿«é€ŸéªŒè¯æµç¨‹ |
| **5,000** | **~8-10GB** | **2-4h/epoch** | **æ¨èï¼šå¹³è¡¡æ•ˆæœä¸é€Ÿåº¦** |
| 8,000 | ~10-12GB | 4-6h/epoch | è¿½æ±‚æ›´å¥½æ•ˆæœ |
| 10,000+ | ~12GB+ | 6+h/epoch | éœ€è¦æ›´å¤šå†…å­˜ |

## ğŸ’¡ é€‰æ‹©æ•°æ®æºå»ºè®®

ä½ æœ‰ä¸¤ä¸ªæ•°æ®æºå¯é€‰ï¼š

### é€‰é¡¹1ï¼š`sft_train_dataset.parquet`ï¼ˆæ¨èï¼‰

**ä¼˜ç‚¹**ï¼š
- âœ… å·²ç»æ˜¯parquetæ ¼å¼ï¼Œè¯»å–æ›´å¿«
- âœ… æ•°æ®å·²ç»é¢„å¤„ç†å¥½
- âœ… ä¸ç°æœ‰è®­ç»ƒæµç¨‹å…¼å®¹

**ä½¿ç”¨**ï¼š
```bash
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_5k.parquet \
    --num_samples 5000
```

### é€‰é¡¹2ï¼š`alpaca_gpt4_data_zh.json`

**ä¼˜ç‚¹**ï¼š
- âœ… é«˜è´¨é‡GPT-4ç”Ÿæˆæ•°æ®
- âœ… é€‚åˆå¯¹è¯ä»»åŠ¡

**ä½¿ç”¨**ï¼š
```bash
python prepare_small_sft_data.py \
    --input data/alpaca_gpt4_data_zh.json \
    --output data/sft_5k.parquet \
    --num_samples 5000
```

**å»ºè®®**ï¼šå¦‚æœä½ ä¸ç¡®å®šï¼Œ**ä¼˜å…ˆé€‰æ‹© `sft_train_dataset.parquet`**ï¼Œå› ä¸ºå®ƒå·²ç»è¿‡é¢„å¤„ç†ã€‚

## ğŸ”§ å†…å­˜ä¼˜åŒ–æŠ€å·§

å¦‚æœ5000æ ·æœ¬è¿˜æ˜¯å†…å­˜ä¸å¤Ÿï¼š

### 1. å‡å°‘æ ·æœ¬æ•°
```bash
./quick_start_sft_small.sh --samples 3000
```

### 2. å‡å°‘åºåˆ—é•¿åº¦
ä¿®æ”¹ `config.py` ä¸­çš„ `TrainConfigSFTSmall`ï¼š
```python
max_seq_len: int = 256  # ä»512é™åˆ°256
```

### 3. ä½¿ç”¨å•GPU
```bash
python train_low_mem.py train --is_finetune=True
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

ä½¿ç”¨5000æ ·æœ¬è®­ç»ƒ3ä¸ªepochåï¼š

| æŒ‡æ ‡ | é¢„æœŸå€¼ |
|-----|-------|
| è®­ç»ƒLoss | 0.5-1.0 |
| éªŒè¯BLEU | 0.3-0.5 |
| æ¨¡å‹å¤§å° | ~700MB |
| æ€»è®­ç»ƒæ—¶é•¿ | 6-12å°æ—¶ |

## ğŸ“ è®­ç»ƒç›‘æ§

### ç›‘æ§å†…å­˜ä½¿ç”¨
```bash
# ç»ˆç«¯1ï¼šè®­ç»ƒ
./quick_start_sft_small.sh

# ç»ˆç«¯2ï¼šç›‘æ§
watch -n 2 'free -h && echo "---GPU---" && nvidia-smi'
```

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
```bash
tail -f logs/*.log
```

### æŸ¥çœ‹è®­ç»ƒè¿›åº¦
è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºï¼š
- å½“å‰epochå’Œstep
- å®æ—¶loss
- å†…å­˜ä½¿ç”¨æƒ…å†µ
- é¢„è®¡å‰©ä½™æ—¶é—´

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®è´¨é‡ > æ•°æ®æ•°é‡**ï¼š5000æ¡é«˜è´¨é‡æ•°æ®æ¯”10000æ¡ä½è´¨é‡æ•°æ®æ•ˆæœæ›´å¥½
2. **é¿å…è¿‡æ‹Ÿåˆ**ï¼šå°æ•°æ®é›†å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œå»ºè®®åªè®­ç»ƒ3-5ä¸ªepoch
3. **ä¿å­˜æœ€ä½³æ¨¡å‹**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨ä¿å­˜éªŒè¯é›†BLEUæœ€é«˜çš„æ¨¡å‹
4. **ç£ç›˜ç©ºé—´**ï¼šç¡®ä¿è‡³å°‘æœ‰5GBå¯ç”¨ç£ç›˜ç©ºé—´ï¼ˆç”¨äºä¿å­˜checkpointï¼‰

## ğŸ“ å®Œæ•´ç¤ºä¾‹

```bash
# åœºæ™¯ï¼šä»sft_train_dataset.parqueté‡‡æ ·5000æ¡æ•°æ®è¿›è¡ŒSFTè®­ç»ƒ

# æ­¥éª¤1ï¼šæŸ¥çœ‹å¯ç”¨æ•°æ®
ls -lh data/*.parquet

# æ­¥éª¤2ï¼šé‡‡æ ·æ•°æ®
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_5k.parquet \
    --num_samples 5000 \
    --valid_ratio 0.1

# æ­¥éª¤3ï¼šæŸ¥çœ‹é‡‡æ ·ç»“æœ
python -c "
import pandas as pd
df = pd.read_parquet('data/sft_5k_train.parquet')
print(f'è®­ç»ƒé›†æ ·æœ¬æ•°: {len(df)}')
print(f'åˆ—å: {df.columns.tolist()}')
print(f'å‰3ä¸ªæ ·æœ¬:')
print(df.head(3))
"

# æ­¥éª¤4ï¼šå¼€å§‹è®­ç»ƒ
accelerate launch --multi_gpu --num_processes 2 ./train_low_mem.py train --is_finetune=True

# æ­¥éª¤5ï¼šç›‘æ§è®­ç»ƒï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
watch -n 2 'free -h && echo "---GPU---" && nvidia-smi'
```

## ğŸ‰ æ€»ç»“

å¯¹äºä½ çš„16Gå†…å­˜ç¯å¢ƒï¼š

1. âœ… **æ¨èä½¿ç”¨5,000è®­ç»ƒæ ·æœ¬**
2. âœ… **ä¼˜å…ˆé€‰æ‹© `sft_train_dataset.parquet` ä½œä¸ºæ•°æ®æº**
3. âœ… **ä½¿ç”¨ `quick_start_sft_small.sh` ä¸€é”®å¯åŠ¨**
4. âœ… **é¢„æœŸå†…å­˜å ç”¨ï¼š8-10GB**
5. âœ… **é¢„æœŸè®­ç»ƒæ—¶é•¿ï¼š6-12å°æ—¶ï¼ˆ3ä¸ªepochï¼‰**

ç°åœ¨å°±å¼€å§‹å§ï¼ğŸš€

```bash
./quick_start_sft_small.sh
```

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ [`SFT_SMALL_DATASET_GUIDE.md`](SFT_SMALL_DATASET_GUIDE.md) è·å–æ›´å¤šå¸®åŠ©ã€‚
