# é¡¹ç›®è®­ç»ƒè„šæœ¬è¯´æ˜

## ğŸ“ æ–‡ä»¶æ¸…å•

æœ¬é¡¹ç›®åŒ…å«ä»¥ä¸‹è®­ç»ƒç›¸å…³æ–‡ä»¶ï¼š

### è®­ç»ƒè„šæœ¬

1. **`train_low_mem.py`** - åŸå§‹æ‰‹åŠ¨è®­ç»ƒå¾ªç¯å®ç°
   - ä½¿ç”¨ `accelerate` æ‰‹åŠ¨å®ç°è®­ç»ƒå¾ªç¯
   - è‡ªå®šä¹‰ä½å†…å­˜ä¼˜åŒ–
   - ä»£ç é‡ï¼š~850è¡Œ

2. **`train_with_transformers_trainer.py`** - Transformers Trainer APIå®ç°
   - ä½¿ç”¨ Transformers åŸç”Ÿ `Trainer` API
   - è‡ªåŠ¨å¤„ç†è®­ç»ƒã€è¯„ä¼°ã€ä¿å­˜
   - ä»£ç é‡ï¼š~200è¡Œ
   - âš ï¸ **ä¹‹å‰è¯¯å‘½åä¸º `train_with_llamafactory.py`**

3. **`train_with_real_llamafactory.py`** - çœŸæ­£çš„ LLaMA-Factoryå®ç°
   - ä½¿ç”¨ `llmtuner` åº“ï¼ˆLLaMA-Factoryçš„åŒ…åï¼‰
   - é…ç½®é©±åŠ¨ï¼ˆYAMLï¼‰
   - ä»£ç é‡ï¼š~100è¡Œ

### å¯åŠ¨è„šæœ¬

4. **`run_multi_gpu_examples.sh`** - å¤šGPUè®­ç»ƒå¯åŠ¨ç¤ºä¾‹
   - å±•ç¤º6ç§ä¸åŒçš„å¤šGPUå¯åŠ¨æ–¹å¼
   - äº¤äº’å¼èœå•é€‰æ‹©

### æ–‡æ¡£

5. **`TRAINING_METHODS_COMPARISON.md`** - è®­ç»ƒæ–¹å¼å¯¹æ¯”
   - è¯¦ç»†å¯¹æ¯”ä¸‰ç§è®­ç»ƒå®ç°
   - ä½¿ç”¨åœºæ™¯æ¨è

6. **`MULTI_GPU_TRAINING_GUIDE.md`** - å¤šGPUè®­ç»ƒæŒ‡å—
   - å¤šGPUè®­ç»ƒæ–¹å¼è¯¦è§£
   - æ€§èƒ½å¯¹æ¯”å’Œæ¨è

7. **`README_TRAINING.md`** - æœ¬æ–‡ä»¶
   - é¡¹ç›®è®­ç»ƒè„šæœ¬æ€»è§ˆ

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æ¨èæ–¹å¼ï¼šä½¿ç”¨ Transformers Trainer

```bash
# å•GPU
python train_with_transformers_trainer.py

# å¤šGPUï¼ˆæ¨ètorchrunï¼‰
torchrun --nproc_per_node=2 train_with_transformers_trainer.py

# å¤šGPUï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼Œæœ€ç®€å•ï¼‰
CUDA_VISIBLE_DEVICES=0,1 python train_with_transformers_trainer.py
```

### ä½¿ç”¨çœŸæ­£çš„ LLaMA-Factory

```bash
# é¦–å…ˆå®‰è£…
pip install llmtuner

# è¿è¡Œ
python train_with_real_llamafactory.py

# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œ
llamafactory-cli train llamafactory_config.yaml
```

### ä½¿ç”¨åŸå§‹æ‰‹åŠ¨è®­ç»ƒå¾ªç¯

```bash
# éœ€è¦accelerate
accelerate launch --multi_gpu --num_processes=2 train_low_mem.py
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: å“ªä¸ªè„šæœ¬æœ€å¥½ç”¨ï¼Ÿ

**A**: å–å†³äºä½ çš„éœ€æ±‚ï¼š
- **å¿«é€Ÿå¼€å‘**: `train_with_real_llamafactory.py`ï¼ˆæœ€ç®€å•ï¼‰
- **æ ‡å‡†è®­ç»ƒ**: `train_with_transformers_trainer.py`ï¼ˆæ¨èï¼Œå¹³è¡¡ï¼‰
- **ç ”ç©¶å®éªŒ**: `train_low_mem.py`ï¼ˆæœ€çµæ´»ï¼‰

### Q2: ä¸ºä»€ä¹ˆæœ‰ä¸ªæ–‡ä»¶å« `train_with_llamafactory.py`ï¼Ÿ

**A**: è¿™æ˜¯ä¸€ä¸ª**å‘½åé”™è¯¯**ï¼
- å®ƒå®é™…ä¸Šä½¿ç”¨çš„æ˜¯ **Transformers Trainer**ï¼Œä¸æ˜¯ LLaMA-Factory
- å·²é‡å‘½åä¸º `train_with_transformers_trainer.py`
- çœŸæ­£çš„ LLaMA-Factory å®ç°åœ¨ `train_with_real_llamafactory.py`

### Q3: å¤šGPUè®­ç»ƒä¸€å®šè¦ç”¨ accelerate å—ï¼Ÿ

**A**: **ä¸éœ€è¦ï¼** Transformers Trainer æ”¯æŒå¤šç§æ–¹å¼ï¼š
- `torchrun`ï¼ˆæ¨èï¼Œæ— éœ€é¢å¤–ä¾èµ–ï¼‰
- è‡ªåŠ¨æ£€æµ‹ï¼ˆæœ€ç®€å•ï¼‰
- `accelerate`ï¼ˆæœ€çµæ´»ï¼‰
- `DeepSpeed`ï¼ˆå¤§æ¨¡å‹ï¼‰

è¯¦è§ [MULTI_GPU_TRAINING_GUIDE.md](MULTI_GPU_TRAINING_GUIDE.md)

### Q4: ä¸‰ç§è®­ç»ƒæ–¹å¼æ€§èƒ½æœ‰å·®å¼‚å—ï¼Ÿ

**A**: æ€§èƒ½å·®å¼‚å¾ˆå°ï¼ˆ<5%ï¼‰ï¼Œä¸»è¦åŒºåˆ«åœ¨äºï¼š
- **ä»£ç å¤æ‚åº¦**: æ‰‹åŠ¨å¾ªç¯ > Trainer > LLaMA-Factory
- **çµæ´»æ€§**: æ‰‹åŠ¨å¾ªç¯ > Trainer > LLaMA-Factory
- **æ˜“ç”¨æ€§**: LLaMA-Factory > Trainer > æ‰‹åŠ¨å¾ªç¯

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- [è®­ç»ƒæ–¹å¼å¯¹æ¯”](TRAINING_METHODS_COMPARISON.md) - ä¸‰ç§è®­ç»ƒå®ç°çš„è¯¦ç»†å¯¹æ¯”
- [å¤šGPUè®­ç»ƒæŒ‡å—](MULTI_GPU_TRAINING_GUIDE.md) - å¤šGPUè®­ç»ƒæ–¹å¼è¯¦è§£

---

## ğŸ”§ ä¾èµ–å®‰è£…

### åŸºç¡€ä¾èµ–ï¼ˆæ‰€æœ‰è„šæœ¬ï¼‰
```bash
pip install torch transformers datasets
```

### Transformers Trainer
```bash
pip install torch_optimizer  # å¯é€‰ï¼Œç”¨äºAdafactorä¼˜åŒ–å™¨
```

### æ‰‹åŠ¨è®­ç»ƒå¾ªç¯
```bash
pip install accelerate
```

### çœŸæ­£çš„ LLaMA-Factory
```bash
pip install llmtuner
```

---

## ğŸ“ æ€»ç»“

| è„šæœ¬ | ä½¿ç”¨çš„æŠ€æœ¯ | æ¨èåœºæ™¯ |
|------|-----------|---------|
| `train_low_mem.py` | Accelerator + æ‰‹åŠ¨å¾ªç¯ | ç ”ç©¶å®éªŒ |
| `train_with_transformers_trainer.py` | Transformers Trainer | æ ‡å‡†è®­ç»ƒï¼ˆæ¨èï¼‰ |
| `train_with_real_llamafactory.py` | LLaMA-Factory (llmtuner) | å¿«é€Ÿå¼€å‘ |

**æ–°æ‰‹æ¨è**: ä» `train_with_transformers_trainer.py` å¼€å§‹ï¼
