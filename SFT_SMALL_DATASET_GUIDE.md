# SFTå°æ•°æ®é›†è®­ç»ƒæŒ‡å— - 16Gå†…å­˜ä¼˜åŒ–ç‰ˆ

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—å¸®åŠ©ä½ åœ¨**16Gå†…å­˜**ç¯å¢ƒä¸‹ï¼Œä»å¤§æ•°æ®é›†ä¸­é‡‡æ ·åˆé€‚æ•°é‡çš„æ•°æ®è¿›è¡ŒSFTï¼ˆSupervised Fine-Tuningï¼‰è®­ç»ƒã€‚

## ğŸ¯ å†…å­˜ä¸æ•°æ®é‡å¯¹åº”å…³ç³»

æ ¹æ®ä½ çš„å†…å­˜é™åˆ¶ï¼ˆ16Gï¼Œå¯ç”¨çº¦13Gï¼‰ï¼Œæ¨èçš„æ•°æ®é‡ï¼š

| å¯ç”¨å†…å­˜ | æ¨èè®­ç»ƒæ ·æœ¬æ•° | éªŒè¯æ ·æœ¬æ•° | é¢„æœŸå†…å­˜å ç”¨ | è®­ç»ƒæ—¶é•¿ï¼ˆä¼°ç®—ï¼‰ |
|---------|--------------|-----------|-------------|----------------|
| 13GB    | 3,000-5,000  | 300-500   | ~8-10GB     | 2-4å°æ—¶/epoch  |
| 16GB    | 5,000-8,000  | 500-800   | ~10-12GB    | 3-6å°æ—¶/epoch  |
| 20GB+   | 10,000+      | 1,000+    | ~12GB+      | 6+å°æ—¶/epoch   |

**æ¨èé…ç½®ï¼ˆ16Gå†…å­˜ï¼‰**ï¼š
- âœ… **è®­ç»ƒæ ·æœ¬ï¼š5,000**
- âœ… **éªŒè¯æ ·æœ¬ï¼š500**
- âœ… **æ€»è®¡ï¼š5,500æ ·æœ¬**

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1ï¼šå‡†å¤‡å°æ•°æ®é›†

ä½ æœ‰ä¸¤ä¸ªæ•°æ®æºå¯é€‰ï¼š

#### é€‰é¡¹Aï¼šä»ç°æœ‰çš„SFTè®­ç»ƒé›†é‡‡æ ·ï¼ˆæ¨èï¼‰

```bash
# ä»sft_train_dataset.parqueté‡‡æ ·5000ä¸ªæ ·æœ¬
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_small.parquet \
    --num_samples 5000 \
    --valid_ratio 0.1
```

#### é€‰é¡¹Bï¼šä»JSONæ–‡ä»¶é‡‡æ ·

```bash
# ä»alpaca_gpt4_data_zh.jsoné‡‡æ ·5000ä¸ªæ ·æœ¬
python prepare_small_sft_data.py \
    --input data/alpaca_gpt4_data_zh.json \
    --output data/sft_small.parquet \
    --num_samples 5000 \
    --valid_ratio 0.1
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `data/sft_small_train.parquet` - è®­ç»ƒé›†ï¼ˆ5,000æ ·æœ¬ï¼‰
- `data/sft_small_valid.parquet` - éªŒè¯é›†ï¼ˆ500æ ·æœ¬ï¼‰

### æ­¥éª¤2ï¼šä¿®æ”¹é…ç½®æ–‡ä»¶

ç¼–è¾‘ `config.py`ï¼Œä¿®æ”¹SFTé…ç½®ï¼š

```python
class TrainConfigSFT(TrainConfig):
    # ä¿®æ”¹æ•°æ®æ–‡ä»¶è·¯å¾„
    train_file = './data/sft_small_train.parquet'
    validation_file = './data/sft_small_valid.parquet'
    
    # å…¶ä»–é…ç½®ä¿æŒä¸å˜
    batch_size_per_gpu = 1
    gradient_accumulation_steps = 8
    epochs = 3  # å°æ•°æ®é›†å¯ä»¥è®­ç»ƒæ›´å¤šepoch
```

### æ­¥éª¤3ï¼šå¼€å§‹è®­ç»ƒ

```bash
# ä½¿ç”¨ä½å†…å­˜æ¨¡å¼è®­ç»ƒ
accelerate launch --multi_gpu --num_processes 2 ./train_low_mem.py train --is_finetune=True
```

## ğŸ“Š ä¸åŒæ ·æœ¬æ•°çš„å†…å­˜ä¼°ç®—

è„šæœ¬ä¼šè‡ªåŠ¨ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼š

```bash
# æµ‹è¯•3000æ ·æœ¬
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_3k.parquet \
    --num_samples 3000

# æµ‹è¯•5000æ ·æœ¬
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_5k.parquet \
    --num_samples 5000

# æµ‹è¯•8000æ ·æœ¬
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_8k.parquet \
    --num_samples 8000
```

## ğŸ”§ é«˜çº§é€‰é¡¹

### è‡ªå®šä¹‰éªŒè¯é›†æ¯”ä¾‹

```bash
# ä½¿ç”¨20%ä½œä¸ºéªŒè¯é›†
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_small.parquet \
    --num_samples 5000 \
    --valid_ratio 0.2
```

### æŒ‡å®šéšæœºç§å­ï¼ˆä¿è¯å¯å¤ç°ï¼‰

```bash
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_small.parquet \
    --num_samples 5000 \
    --seed 123
```

## ğŸ’¡ è®­ç»ƒä¼˜åŒ–å»ºè®®

### 1. å°æ•°æ®é›†è®­ç»ƒç­–ç•¥

- **å¢åŠ epochæ•°**ï¼šå°æ•°æ®é›†å¯ä»¥è®­ç»ƒæ›´å¤šepochï¼ˆ3-5ä¸ªï¼‰
- **ä½¿ç”¨æ•°æ®å¢å¼º**ï¼šå¯ä»¥è€ƒè™‘æ·»åŠ æ•°æ®å¢å¼ºæŠ€æœ¯
- **æ—©åœç­–ç•¥**ï¼šç›‘æ§éªŒè¯é›†BLEUåˆ†æ•°ï¼Œé¿å…è¿‡æ‹Ÿåˆ

### 2. å†…å­˜ä¼˜åŒ–é…ç½®

åœ¨ `config.py` ä¸­ï¼š

```python
class TrainConfigSFT(TrainConfig):
    # æè‡´ä½å†…å­˜é…ç½®
    batch_size_per_gpu = 1          # æœ€å°batch size
    gradient_accumulation_steps = 8  # æ¢¯åº¦ç´¯ç§¯è¡¥å¿
    max_seq_len = 512               # é™åˆ¶åºåˆ—é•¿åº¦
    
    # è®­ç»ƒé…ç½®
    epochs = 3                      # å°æ•°æ®é›†å¤šè®­ç»ƒå‡ è½®
    save_steps = 200                # æ›´é¢‘ç¹ä¿å­˜
    logging_steps = 50              # æ›´é¢‘ç¹è®°å½•
```

### 3. ç›‘æ§å†…å­˜ä½¿ç”¨

è®­ç»ƒæ—¶åœ¨å¦ä¸€ä¸ªç»ˆç«¯ç›‘æ§ï¼š

```bash
# ç›‘æ§ç³»ç»Ÿå†…å­˜
watch -n 2 'free -h'

# ç›‘æ§GPUå†…å­˜
watch -n 2 'nvidia-smi'
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

ä½¿ç”¨5,000æ ·æœ¬è®­ç»ƒçš„é¢„æœŸæ•ˆæœï¼š

| æŒ‡æ ‡ | é¢„æœŸå€¼ | è¯´æ˜ |
|-----|-------|------|
| è®­ç»ƒæ—¶é•¿ | 2-4å°æ—¶/epoch | å–å†³äºGPUæ€§èƒ½ |
| å†…å­˜å ç”¨ | 8-10GB | åŒGPUæ€»è®¡ |
| BLEUåˆ†æ•° | 0.3-0.5 | 3ä¸ªepochå |
| æ¨¡å‹å¤§å° | ~700MB | å•ä¸ªcheckpoint |

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: å†…å­˜è¿˜æ˜¯ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å‡å°‘æ ·æœ¬æ•°åˆ°3,000
2. å‡å°‘ `max_seq_len` åˆ° 256
3. ä½¿ç”¨å•GPUè®­ç»ƒï¼ˆè™½ç„¶æ›´æ…¢ï¼‰

```bash
# å•GPUè®­ç»ƒ
python train_low_mem.py train --is_finetune=True
```

### Q2: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å¢åŠ  `batch_size_per_gpu` åˆ° 2ï¼ˆå¦‚æœå†…å­˜å…è®¸ï¼‰
2. å‡å°‘ `gradient_accumulation_steps` åˆ° 4
3. ä½¿ç”¨æ›´å°‘çš„æ ·æœ¬ï¼ˆ3,000ï¼‰

### Q3: å¦‚ä½•éªŒè¯æ•°æ®è´¨é‡ï¼Ÿ

```python
# æŸ¥çœ‹é‡‡æ ·åçš„æ•°æ®
import pandas as pd

df = pd.read_parquet('data/sft_small_train.parquet')
print(f"æ ·æœ¬æ•°: {len(df)}")
print(f"åˆ—å: {df.columns.tolist()}")
print(f"\nå‰3ä¸ªæ ·æœ¬:")
print(df.head(3))
```

### Q4: å°æ•°æ®é›†ä¼šè¿‡æ‹Ÿåˆå—ï¼Ÿ

**æ˜¯çš„**ï¼Œå°æ•°æ®é›†å®¹æ˜“è¿‡æ‹Ÿåˆã€‚å»ºè®®ï¼š
1. ç›‘æ§è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„BLEUåˆ†æ•°å·®å¼‚
2. ä½¿ç”¨æ—©åœï¼ˆearly stoppingï¼‰
3. è®­ç»ƒ3-5ä¸ªepochååœæ­¢
4. ä¿å­˜éªŒè¯é›†BLEUæœ€é«˜çš„æ¨¡å‹

## ğŸ“ å®Œæ•´ç¤ºä¾‹

```bash
# 1. å‡†å¤‡æ•°æ®ï¼ˆ5000æ ·æœ¬ï¼‰
python prepare_small_sft_data.py \
    --input data/sft_train_dataset.parquet \
    --output data/sft_5k.parquet \
    --num_samples 5000 \
    --valid_ratio 0.1

# 2. ä¿®æ”¹config.pyä¸­çš„æ–‡ä»¶è·¯å¾„
# train_file = './data/sft_5k_train.parquet'
# validation_file = './data/sft_5k_valid.parquet'

# 3. å¼€å§‹è®­ç»ƒ
accelerate launch --multi_gpu --num_processes 2 ./train_low_mem.py train --is_finetune=True

# 4. ç›‘æ§å†…å­˜ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
watch -n 2 'free -h && echo "---GPU---" && nvidia-smi'
```

## ğŸ“ æ•°æ®é‡é€‰æ‹©å»ºè®®

æ ¹æ®ä½ çš„ç›®æ ‡é€‰æ‹©åˆé€‚çš„æ•°æ®é‡ï¼š

| ç›®æ ‡ | æ¨èæ ·æœ¬æ•° | è¯´æ˜ |
|-----|-----------|------|
| å¿«é€ŸéªŒè¯æµç¨‹ | 1,000-2,000 | å¿«é€Ÿæµ‹è¯•ï¼Œ1å°æ—¶å†…å®Œæˆ |
| **å¹³è¡¡è®­ç»ƒï¼ˆæ¨èï¼‰** | **5,000** | **æ•ˆæœä¸é€Ÿåº¦å¹³è¡¡** |
| è¿½æ±‚æ›´å¥½æ•ˆæœ | 8,000-10,000 | éœ€è¦æ›´å¤šå†…å­˜å’Œæ—¶é—´ |
| å®Œæ•´è®­ç»ƒ | 20,000+ | éœ€è¦32GB+å†…å­˜ |

## âœ… æ€»ç»“

å¯¹äºä½ çš„16Gå†…å­˜ç¯å¢ƒï¼š

1. âœ… **æ¨èä½¿ç”¨5,000è®­ç»ƒæ ·æœ¬ + 500éªŒè¯æ ·æœ¬**
2. âœ… **ä½¿ç”¨ `prepare_small_sft_data.py` è„šæœ¬é‡‡æ ·**
3. âœ… **ä½¿ç”¨ `train_low_mem.py` è¿›è¡Œè®­ç»ƒ**
4. âœ… **é¢„æœŸå†…å­˜å ç”¨ï¼š8-10GB**
5. âœ… **é¢„æœŸè®­ç»ƒæ—¶é•¿ï¼š2-4å°æ—¶/epoch**

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
