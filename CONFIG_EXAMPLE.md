# å¤§æ•°æ®é›†é¢„è®­ç»ƒé…ç½®ç¤ºä¾‹

## ğŸ“ æ•°æ®æ–‡ä»¶å‡†å¤‡

### 1. æ•°æ®æ ¼å¼è¦æ±‚

æ•°æ®æ–‡ä»¶å¿…é¡»æ˜¯ **Parquet æ ¼å¼**ï¼ŒåŒ…å«ä»¥ä¸‹ä¸¤åˆ—ï¼š

| åˆ—å | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|
| `prompt` | string | è¾“å…¥æ–‡æœ¬ï¼ˆé—®é¢˜/ä¸Šä¸‹æ–‡ï¼‰ | "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ" |
| `response` | string | è¾“å‡ºæ–‡æœ¬ï¼ˆç­”æ¡ˆ/å›å¤ï¼‰ | "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯..." |

### 2. æ•°æ®æ–‡ä»¶è·¯å¾„é…ç½®

åœ¨ [`config.py`](config.py) ä¸­æ‰¾åˆ° `TrainConfigPretrainLarge` ç±»ï¼Œä¿®æ”¹ä»¥ä¸‹è·¯å¾„ï¼š

```python
@dataclass
class TrainConfigPretrainLarge:
    # ... å…¶ä»–é…ç½® ...
    
    # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®æ–‡ä»¶è·¯å¾„
    train_file: str = PROJECT_ROOT + '/data/pretrain_train_10m.parquet'      # 1000ä¸‡è®­ç»ƒæ•°æ®
    validation_file: str = PROJECT_ROOT + '/data/pretrain_valid_100k.parquet'  # 10ä¸‡éªŒè¯æ•°æ®
    test_file: str = PROJECT_ROOT + '/data/pretrain_test.parquet'             # æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰
```

### 3. æ•°æ®å‡†å¤‡ç¤ºä¾‹

#### æ–¹æ³•A: ä»CSVè½¬æ¢ä¸ºParquet

```python
import pandas as pd

# è¯»å–CSVæ–‡ä»¶
df = pd.read_csv('your_data.csv')

# ç¡®ä¿åŒ…å« prompt å’Œ response åˆ—
# df = df[['prompt', 'response']]

# ä¿å­˜ä¸ºParquetæ ¼å¼
df.to_parquet('data/pretrain_train_10m.parquet', index=False)
```

#### æ–¹æ³•B: ä»JSONè½¬æ¢ä¸ºParquet

```python
import pandas as pd
import json

# è¯»å–JSONæ–‡ä»¶
with open('your_data.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# è½¬æ¢ä¸ºDataFrame
df = pd.DataFrame(data)

# ç¡®ä¿åŒ…å« prompt å’Œ response åˆ—
# å¦‚æœåˆ—åä¸åŒï¼Œéœ€è¦é‡å‘½åï¼š
# df = df.rename(columns={'question': 'prompt', 'answer': 'response'})

# ä¿å­˜ä¸ºParquetæ ¼å¼
df.to_parquet('data/pretrain_train_10m.parquet', index=False)
```

#### æ–¹æ³•C: ä»JSONLè½¬æ¢ä¸ºParquet

```python
import pandas as pd

# è¯»å–JSONLæ–‡ä»¶
data = []
with open('your_data.jsonl', 'r', encoding='utf-8') as f:
    for line in f:
        data.append(json.loads(line))

# è½¬æ¢ä¸ºDataFrame
df = pd.DataFrame(data)

# ä¿å­˜ä¸ºParquetæ ¼å¼
df.to_parquet('data/pretrain_train_10m.parquet', index=False)
```

### 4. æ•°æ®åˆ†å‰²ç¤ºä¾‹

å¦‚æœä½ æœ‰ä¸€ä¸ªå¤§æ–‡ä»¶ï¼Œéœ€è¦åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼š

```python
import pandas as pd
from sklearn.model_selection import train_test_split

# è¯»å–æ•°æ®
df = pd.read_parquet('your_large_data.parquet')

# åˆ†å‰²æ•°æ®ï¼š90%è®­ç»ƒï¼Œ10%éªŒè¯
train_df, valid_df = train_test_split(df, test_size=0.1, random_state=42)

# ä¿å­˜
train_df.to_parquet('data/pretrain_train_10m.parquet', index=False)
valid_df.to_parquet('data/pretrain_valid_100k.parquet', index=False)

print(f"è®­ç»ƒé›†å¤§å°: {len(train_df)}")
print(f"éªŒè¯é›†å¤§å°: {len(valid_df)}")
```

### 5. æ•°æ®è´¨é‡æ£€æŸ¥

```python
import pandas as pd

# è¯»å–æ•°æ®
df = pd.read_parquet('data/pretrain_train_10m.parquet')

# æ£€æŸ¥æ•°æ®
print("æ•°æ®å½¢çŠ¶:", df.shape)
print("\nåˆ—å:", df.columns.tolist())
print("\nå‰5è¡Œ:")
print(df.head())

# æ£€æŸ¥ç©ºå€¼
print("\nç©ºå€¼ç»Ÿè®¡:")
print(df.isnull().sum())

# æ£€æŸ¥æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ
df['prompt_len'] = df['prompt'].str.len()
df['response_len'] = df['response'].str.len()
print("\nprompté•¿åº¦ç»Ÿè®¡:")
print(df['prompt_len'].describe())
print("\nresponseé•¿åº¦ç»Ÿè®¡:")
print(df['response_len'].describe())
```

## ğŸ”§ é…ç½®å‚æ•°è¯´æ˜

### æ ¸å¿ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒæ•´å»ºè®® |
|------|--------|------|----------|
| `epochs` | 3 | è®­ç»ƒè½®æ•° | å¤§æ•°æ®é›†3-5ä¸ªepochè¶³å¤Ÿ |
| `batch_size_per_gpu` | 32 | æ¯å¼ GPUçš„batch size | æ˜¾å­˜ä¸è¶³æ—¶é™åˆ°24æˆ–16 |
| `gradient_accumulation_steps` | 2 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° | å†…å­˜ä¸è¶³æ—¶å¢åŠ åˆ°4 |
| `max_seq_len` | 192 | æœ€å¤§åºåˆ—é•¿åº¦ | é¢„è®­ç»ƒ192è¶³å¤Ÿï¼Œå¯é™åˆ°128 |
| `learn_rate` | 0.0001 | å­¦ä¹ ç‡ | lossä¸ä¸‹é™æ—¶é™ä½åˆ°5e-5 |
| `warmup_steps` | 1024 | é¢„çƒ­æ­¥æ•° | å¯å¢åŠ åˆ°2048 |
| `save_steps` | 5000 | ä¿å­˜é—´éš” | å¯è°ƒæ•´ä¸º2000-10000 |
| `logging_steps` | 100 | æ—¥å¿—é—´éš” | å¯è°ƒæ•´ä¸º50-200 |

### è·¯å¾„å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `tokenizer_dir` | `model_save/my_tokenizer_sp/` | tokenizerè·¯å¾„ |
| `train_file` | `data/pretrain_train_10m.parquet` | è®­ç»ƒæ•°æ®è·¯å¾„ |
| `validation_file` | `data/pretrain_valid_100k.parquet` | éªŒè¯æ•°æ®è·¯å¾„ |
| `model_file` | `model_save/pretrain_large/chat_small_t5.{}.bin` | æ¨¡å‹ä¿å­˜è·¯å¾„ |
| `train_state_dir` | `model_save/pretrain_large/train_latest_state` | è®­ç»ƒçŠ¶æ€ä¿å­˜è·¯å¾„ |

## ğŸ“Š èµ„æºå ç”¨é¢„ä¼°

### å†…å­˜å ç”¨

| é…ç½® | é¢„ä¼°å†…å­˜å ç”¨ | è¯´æ˜ |
|------|-------------|------|
| batch_size=32, grad_accum=2 | 8-10GB | æ¨èé…ç½® |
| batch_size=24, grad_accum=2 | 7-9GB | å†…å­˜ç´§å¼ æ—¶ |
| batch_size=16, grad_accum=4 | 6-8GB | æä½å†…å­˜ |

### æ˜¾å­˜å ç”¨

| é…ç½® | é¢„ä¼°æ˜¾å­˜å ç”¨/GPU | è¯´æ˜ |
|------|-----------------|------|
| max_seq_len=192, batch_size=32 | 16-18GB | æ¨èé…ç½® |
| max_seq_len=192, batch_size=24 | 12-14GB | æ˜¾å­˜ç´§å¼ æ—¶ |
| max_seq_len=128, batch_size=32 | 10-12GB | çŸ­åºåˆ— |

### è®­ç»ƒæ—¶é—´

| æ•°æ®é‡ | é…ç½® | æ¯epochè€—æ—¶ | 3 epochsæ€»è€—æ—¶ |
|--------|------|------------|---------------|
| 1000ä¸‡ | batch_size=32Ã—3Ã—2=192 | 7-11å°æ—¶ | 21-33å°æ—¶ |
| 1000ä¸‡ | batch_size=24Ã—3Ã—2=144 | 9-14å°æ—¶ | 27-42å°æ—¶ |
| 500ä¸‡ | batch_size=32Ã—3Ã—2=192 | 3.5-5.5å°æ—¶ | 10.5-16.5å°æ—¶ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data

# å°†ä½ çš„æ•°æ®è½¬æ¢ä¸ºparquetæ ¼å¼ï¼ˆå‚è€ƒä¸Šé¢çš„ç¤ºä¾‹ï¼‰
python prepare_data.py
```

### 2. ä¿®æ”¹é…ç½®

ç¼–è¾‘ [`config.py`](config.py)ï¼Œä¿®æ”¹ `TrainConfigPretrainLarge` ä¸­çš„æ•°æ®è·¯å¾„ã€‚

### 3. å¯åŠ¨è®­ç»ƒ

```bash
# æ–¹æ³•1: ä½¿ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬
./start_pretrain_large.sh

# æ–¹æ³•2: æ‰‹åŠ¨å¯åŠ¨
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True
```

### 4. ç›‘æ§è®­ç»ƒ

```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/chat_trainer_low_mem_*.log

# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi
```

## ğŸ” å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•ä¿®æ”¹æ•°æ®è·¯å¾„ï¼Ÿ

**A**: ç¼–è¾‘ [`config.py`](config.py)ï¼Œæ‰¾åˆ° `TrainConfigPretrainLarge` ç±»ï¼Œä¿®æ”¹ `train_file` å’Œ `validation_file` è·¯å¾„ã€‚

### Q2: æ•°æ®é‡ä¸æ˜¯1000ä¸‡æ€ä¹ˆåŠï¼Ÿ

**A**: é…ç½®ä¼šè‡ªåŠ¨é€‚åº”æ•°æ®é‡ï¼Œæ— éœ€ä¿®æ”¹ã€‚åªéœ€ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®å³å¯ã€‚

### Q3: å¦‚ä½•è°ƒæ•´batch_sizeï¼Ÿ

**A**: 
```bash
# æ–¹æ³•1: å‘½ä»¤è¡Œå‚æ•°
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --batch_size_per_gpu=24

# æ–¹æ³•2: ä¿®æ”¹config.pyä¸­çš„batch_size_per_gpu
```

### Q4: å¦‚ä½•ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒï¼Ÿ

**A**:
```bash
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --is_keep_training=True
```

### Q5: å¦‚ä½•ä¿®æ”¹åºåˆ—é•¿åº¦ï¼Ÿ

**A**:
```bash
# æ–¹æ³•1: å‘½ä»¤è¡Œå‚æ•°
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --max_seq_len=128

# æ–¹æ³•2: ä¿®æ”¹config.pyä¸­çš„max_seq_len
```

## ğŸ“ é…ç½®æ¨¡æ¿

### å°æ•°æ®é›†ï¼ˆ100ä¸‡æ ·æœ¬ï¼‰

```python
epochs: int = 5
batch_size_per_gpu: int = 32
gradient_accumulation_steps: int = 2
max_seq_len: int = 192
save_steps: int = 2000
```

### ä¸­ç­‰æ•°æ®é›†ï¼ˆ500ä¸‡æ ·æœ¬ï¼‰

```python
epochs: int = 4
batch_size_per_gpu: int = 32
gradient_accumulation_steps: int = 2
max_seq_len: int = 192
save_steps: int = 3000
```

### å¤§æ•°æ®é›†ï¼ˆ1000ä¸‡æ ·æœ¬ï¼‰- é»˜è®¤é…ç½®

```python
epochs: int = 3
batch_size_per_gpu: int = 32
gradient_accumulation_steps: int = 2
max_seq_len: int = 192
save_steps: int = 5000
```

### è¶…å¤§æ•°æ®é›†ï¼ˆ5000ä¸‡æ ·æœ¬ï¼‰

```python
epochs: int = 2
batch_size_per_gpu: int = 32
gradient_accumulation_steps: int = 2
max_seq_len: int = 192
save_steps: int = 10000
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®å­˜å‚¨ä¼˜åŒ–
- âœ… å°†æ•°æ®æ–‡ä»¶æ”¾åœ¨SSDä¸Šï¼ˆè€ŒéHDDï¼‰
- âœ… ä½¿ç”¨Parquetæ ¼å¼ï¼ˆæ¯”CSVå¿«3-5å€ï¼‰
- âœ… é¢„å…ˆæ¸…æ´—æ•°æ®ï¼Œå»é™¤ç©ºå€¼å’Œå¼‚å¸¸å€¼

### 2. è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–
- âœ… ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆbf16ï¼‰
- âœ… å¢å¤§batch_sizeï¼ˆå……åˆ†åˆ©ç”¨GPUï¼‰
- âœ… å‡å°‘save_stepsï¼ˆå‡å°‘IOå¼€é”€ï¼‰

### 3. å†…å­˜ä¼˜åŒ–
- âœ… å¯ç”¨ultra_low_memæ¨¡å¼
- âœ… ç¦ç”¨num_workers
- âœ… å®šæœŸæ¸…ç†ç¼“å­˜

### 4. æ˜¾å­˜ä¼˜åŒ–
- âœ… ç¼©çŸ­max_seq_len
- âœ… ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
- âœ… ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- [ä¼˜åŒ–æŒ‡å—](OPTIMIZATION_GUIDE.md)
- [è®­ç»ƒè„šæœ¬](train_low_mem.py)
- [é…ç½®æ–‡ä»¶](config.py)
