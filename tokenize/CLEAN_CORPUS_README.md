# ğŸ“– æ–‡æœ¬è¯­æ–™æ¸…æ´—å·¥å…·

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºæ¸…æ´—æ–‡æœ¬è¯­æ–™çš„å·¥å…·ï¼Œå¯ä»¥å°†åŸå§‹æ–‡æœ¬æ–‡ä»¶ï¼ˆå¦‚ç»´åŸºç™¾ç§‘æ•°æ®ï¼‰æ¸…æ´—ä¸ºé€‚åˆ tokenizer è®­ç»ƒçš„æ ¼å¼ã€‚

---

## ğŸ“¦ æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| [clean_corpus.py](./clean_corpus.py) | ä¸»æ¸…æ´—è„šæœ¬ |
| [CLEAN_CORPUS_GUIDE.md](./CLEAN_CORPUS_GUIDE.md) | è¯¦ç»†ä½¿ç”¨æŒ‡å— |
| [run_clean_corpus.sh](./run_clean_corpus.sh) | å¿«é€Ÿä½¿ç”¨è„šæœ¬ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1ï¼šä½¿ç”¨ Python è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /Users/twrong/git/code/ChatLM-mini-Chinese/tokenize

# åŸºæœ¬ç”¨æ³•
python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt

# å¸¦é¢„è§ˆ
python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt \
  --preview
```

### æ–¹æ³• 2ï¼šä½¿ç”¨å¿«é€Ÿè„šæœ¬

```bash
cd /Users/twrong/git/code/ChatLM-mini-Chinese/tokenize

# è¿è¡Œäº¤äº’å¼è„šæœ¬
bash run_clean_corpus.sh
```

---

## âœ¨ ä¸»è¦åŠŸèƒ½

### 1. æ–‡æœ¬æ¸…æ´—
- âœ… å»é™¤ç©ºè¡Œå’Œæ— æ•ˆè¡Œ
- âœ… å»é™¤å¤šä½™ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
- âœ… è¿‡æ»¤è¿‡çŸ­/è¿‡é•¿çš„æ–‡æœ¬
- âœ… æ£€æµ‹å¹¶è¿‡æ»¤åƒåœ¾æ•°æ®

### 2. æ–‡æœ¬åˆå¹¶
- âœ… å°†çŸ­è¡Œåˆå¹¶ä¸ºé€‚åˆè®­ç»ƒçš„æ–‡æœ¬å—
- âœ… è‡ªåŠ¨å¤„ç†è¶…é•¿è¡Œ
- âœ… ä¿æŒè¯­ä¹‰è¿è´¯æ€§

### 3. ç»Ÿè®¡åˆ†æ
- âœ… æ˜¾ç¤ºå¤„ç†è¿›åº¦
- âœ… è¾“å‡ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
- âœ… æ”¯æŒé¢„è§ˆç»“æœ

---

## ğŸ“Š å‚æ•°è¯´æ˜

### å¿…éœ€å‚æ•°

```bash
--input, -i    # è¾“å…¥æ–‡ä»¶è·¯å¾„
--output, -o   # è¾“å‡ºæ–‡ä»¶è·¯å¾„
```

### å¯é€‰å‚æ•°

```bash
--target-length 2048    # ç›®æ ‡æ–‡æœ¬å—é•¿åº¦ï¼ˆé»˜è®¤ï¼š2048ï¼‰
--min-length 10         # å•è¡Œæœ€å°é•¿åº¦ï¼ˆé»˜è®¤ï¼š10ï¼‰
--max-length 50000      # å•è¡Œæœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤ï¼š50000ï¼‰
--encoding utf-8        # æ–‡ä»¶ç¼–ç ï¼ˆé»˜è®¤ï¼šutf-8ï¼‰
--preview               # æ¸…æ´—å®Œæˆåé¢„è§ˆè¾“å‡º
--preview-lines 10      # é¢„è§ˆè¡Œæ•°ï¼ˆé»˜è®¤ï¼š10ï¼‰
```

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šæ ‡å‡†æ¸…æ´—

```bash
python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt
```

**è¾“å‡º**ï¼š
```
ğŸ“– è¯»å–è¾“å…¥æ–‡ä»¶: ../data/wiki.simple.txt
ğŸ“Š æ–‡ä»¶å¤§å°: 1100.00 MB
ğŸ”„ è¯»å–æ–‡ä»¶å†…å®¹...
ğŸ“ æ€»è¡Œæ•°: 5,234,567
ğŸ§¹ æ¸…æ´—å’Œåˆå¹¶æ–‡æœ¬...
å¤„ç†è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5234567/5234567
âœ… ç”Ÿæˆæ–‡æœ¬å—æ•°: 1,234,567
ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
  - æ€»å­—ç¬¦æ•°: 2,500,000,000
  - å¹³å‡å—é•¿åº¦: 2025
  - æœ€çŸ­å—é•¿åº¦: 10
  - æœ€é•¿å—é•¿åº¦: 49999
ğŸ’¾ å†™å…¥è¾“å‡ºæ–‡ä»¶: ../data/my_corpus.txt
âœ… è¾“å‡ºæ–‡ä»¶å¤§å°: 950.00 MB
ğŸ“‰ æ•°æ®å‹ç¼©ç‡: 13.64%
ğŸ‰ æ¸…æ´—å®Œæˆï¼
```

### ç¤ºä¾‹ 2ï¼šè‡ªå®šä¹‰å‚æ•° + é¢„è§ˆ

```bash
python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt \
  --target-length 1024 \
  --min-length 50 \
  --max-length 5000 \
  --preview \
  --preview-lines 5
```

### ç¤ºä¾‹ 3ï¼šå¿«é€Ÿæµ‹è¯•

```bash
# åˆ›å»ºæµ‹è¯•æ–‡ä»¶ï¼ˆå‰ 10000 è¡Œï¼‰
head -10000 ../data/wiki.simple.txt > ../data/test_input.txt

# æ¸…æ´—æµ‹è¯•æ–‡ä»¶
python clean_corpus.py \
  --input ../data/test_input.txt \
  --output ../data/test_output.txt \
  --preview
```

---

## ğŸ”„ å®Œæ•´å·¥ä½œæµç¨‹

### æ­¥éª¤ 1ï¼šæ¸…æ´—è¯­æ–™

```bash
cd /Users/twrong/git/code/ChatLM-mini-Chinese/tokenize

python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt \
  --preview
```

### æ­¥éª¤ 2ï¼šè®­ç»ƒ Tokenizer

```bash
python train_tokenizer.py \
  --method t5-base \
  --wiki-file ../data/my_corpus.txt \
  --output-dir ../model_save/my_tokenizer_wiki \
  --vocab-size 40960 \
  --batch-size 500
```

### æ­¥éª¤ 3ï¼šéªŒè¯ç»“æœ

```bash
# æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
ls -lh ../data/my_corpus.txt

# é¢„è§ˆå†…å®¹
head -20 ../data/my_corpus.txt

# ç»Ÿè®¡è¡Œæ•°
wc -l ../data/my_corpus.txt
```

---

## ğŸ¯ æ¨èé…ç½®

### é…ç½® 1ï¼šæ ‡å‡†é…ç½®ï¼ˆæ¨èï¼‰

é€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯ï¼š

```bash
python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt \
  --target-length 2048 \
  --min-length 10 \
  --max-length 50000
```

### é…ç½® 2ï¼šå¿«é€Ÿé…ç½®

é€‚ç”¨äºå¿«é€Ÿæµ‹è¯•ï¼š

```bash
python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt \
  --target-length 1024 \
  --min-length 50 \
  --max-length 5000
```

### é…ç½® 3ï¼šé«˜è´¨é‡é…ç½®

é€‚ç”¨äºé«˜è´¨é‡è®­ç»ƒï¼š

```bash
python clean_corpus.py \
  --input ../data/wiki.txt \
  --output ../data/my_corpus.txt \
  --target-length 4096 \
  --min-length 100 \
  --max-length 10000
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1ï¼šå†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ `wiki.simple.txt` è€Œä¸æ˜¯ `wiki.txt`
- åˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶
- å¢åŠ ç³»ç»Ÿå†…å­˜

### é—®é¢˜ 2ï¼šæ–‡ä»¶ç¼–ç é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
python clean_corpus.py \
  --input ../data/wiki.txt \
  --output ../data/my_corpus.txt \
  --encoding gbk
```

### é—®é¢˜ 3ï¼šè¾“å‡ºæ–‡ä»¶å¤ªå°

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å‡å° `--min-length` å‚æ•°
- å¢å¤§ `--max-length` å‚æ•°
- æ£€æŸ¥è¾“å…¥æ–‡ä»¶è´¨é‡

### é—®é¢˜ 4ï¼šå¤„ç†é€Ÿåº¦å¤ªæ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ `wiki.simple.txt`
- å¢å¤§ `--target-length` å‚æ•°
- ä½¿ç”¨ SSD ç¡¬ç›˜

---

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

### å¤„ç†é€Ÿåº¦

| æ–‡ä»¶å¤§å° | å¤„ç†æ—¶é—´ | é€Ÿåº¦ |
|---------|---------|------|
| 100 MB | ~10 ç§’ | ~10 MB/s |
| 500 MB | ~50 ç§’ | ~10 MB/s |
| 1 GB | ~2 åˆ†é’Ÿ | ~8 MB/s |

### æ•°æ®å‹ç¼©ç‡

é€šå¸¸å¯ä»¥å‡å°‘ 10-15% çš„æ–‡ä»¶å¤§å°ï¼ˆå»é™¤æ— æ•ˆæ•°æ®ï¼‰ã€‚

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [è¯¦ç»†ä½¿ç”¨æŒ‡å—](./CLEAN_CORPUS_GUIDE.md) - å®Œæ•´çš„ä½¿ç”¨è¯´æ˜
- [Tokenizer è®­ç»ƒæŒ‡å—](./train_tokenizer.py) - è®­ç»ƒ tokenizer
- [é”™è¯¯ä¿®å¤è¯´æ˜](./BUGFIX_TOKENIZER_TRAINING.md) - å¸¸è§é—®é¢˜è§£å†³

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„è¾“å…¥æ–‡ä»¶

| æ–‡ä»¶ | ä¼˜ç‚¹ | ç¼ºç‚¹ | æ¨èåœºæ™¯ |
|------|------|------|---------|
| `wiki.txt` | æ•°æ®å®Œæ•´ | æ–‡ä»¶å¤§ï¼Œå¤„ç†æ…¢ | é«˜è´¨é‡è®­ç»ƒ |
| `wiki.simple.txt` | å¤„ç†å¿« | æ•°æ®è¾ƒå°‘ | å¿«é€Ÿæµ‹è¯• |

### 2. è°ƒæ•´å‚æ•°

- **target-length**ï¼š
  - å°å€¼ï¼ˆ1024ï¼‰ï¼šæ›´å¤šæ–‡æœ¬å—ï¼Œè®­ç»ƒæ›´ç»†è‡´
  - å¤§å€¼ï¼ˆ4096ï¼‰ï¼šæ›´å°‘æ–‡æœ¬å—ï¼Œè®­ç»ƒæ›´å¿«

- **min-length**ï¼š
  - å°å€¼ï¼ˆ10ï¼‰ï¼šä¿ç•™æ›´å¤šæ•°æ®
  - å¤§å€¼ï¼ˆ100ï¼‰ï¼šè¿‡æ»¤ä½è´¨é‡æ•°æ®

### 3. éªŒè¯è¾“å‡ºè´¨é‡

```bash
# é¢„è§ˆè¾“å‡º
python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt \
  --preview \
  --preview-lines 20

# ç»Ÿè®¡ä¿¡æ¯
wc -l ../data/my_corpus.txt  # è¡Œæ•°
wc -c ../data/my_corpus.txt  # å­—èŠ‚æ•°
```

---

## ğŸ‰ æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

- âœ… **ç®€å•æ˜“ç”¨**ï¼šä¸€æ¡å‘½ä»¤å®Œæˆæ¸…æ´—
- âœ… **é«˜æ•ˆå¿«é€Ÿ**ï¼šå¤„ç†é€Ÿåº¦ ~10 MB/s
- âœ… **è´¨é‡ä¿è¯**ï¼šå¤šé‡è¿‡æ»¤è§„åˆ™
- âœ… **çµæ´»é…ç½®**ï¼šä¸°å¯Œçš„å‚æ•°é€‰é¡¹

### æ¨èå‘½ä»¤

```bash
# æœ€æ¨èçš„å‘½ä»¤
cd /Users/twrong/git/code/ChatLM-mini-Chinese/tokenize

python clean_corpus.py \
  --input ../data/wiki.simple.txt \
  --output ../data/my_corpus.txt \
  --target-length 2048 \
  --min-length 10 \
  --max-length 50000 \
  --preview
```

### ä¸‹ä¸€æ­¥

æ¸…æ´—å®Œæˆåï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®­ç»ƒ tokenizerï¼š

```bash
python train_tokenizer.py \
  --method t5-base \
  --wiki-file ../data/my_corpus.txt \
  --output-dir ../model_save/my_tokenizer_wiki \
  --vocab-size 40960 \
  --batch-size 500
```

---

## ğŸ“ è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯
python clean_corpus.py --help

# æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£
cat CLEAN_CORPUS_GUIDE.md
```

---

**ç°åœ¨å¯ä»¥å¼€å§‹æ¸…æ´—æ•°æ®äº†ï¼** ğŸš€

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ [è¯¦ç»†ä½¿ç”¨æŒ‡å—](./CLEAN_CORPUS_GUIDE.md)ã€‚
