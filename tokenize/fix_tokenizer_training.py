#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤ Tokenizer è®­ç»ƒé”™è¯¯

é—®é¢˜ï¼štokenizers åº“åœ¨è®­ç»ƒæ—¶å‡ºç° Rust panic é”™è¯¯
è§£å†³æ–¹æ¡ˆï¼šé¢„å¤„ç†æ•°æ®ï¼Œå»é™¤ç©ºè¡Œå’Œæ— æ•ˆå­—ç¬¦

ä½¿ç”¨æ–¹æ³•ï¼š
    python fix_tokenizer_training.py --input ../data/wiki.simple.txt --output ../data/wiki_clean.txt
"""

import argparse
import os
import re
from tqdm import tqdm


def preprocess_line(line: str) -> str:
    """
    é¢„å¤„ç†å•è¡Œæ–‡æœ¬
    
    Args:
        line: åŸå§‹æ–‡æœ¬è¡Œ
    
    Returns:
        å¤„ç†åçš„æ–‡æœ¬è¡Œ
    """
    # å»é™¤é¦–å°¾ç©ºç™½
    line = line.strip()
    
    # å»é™¤å¤šä½™çš„ç©ºæ ¼
    line = re.sub(r'\s+', ' ', line)
    
    # å»é™¤ç‰¹æ®Šæ§åˆ¶å­—ç¬¦
    line = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f]', '', line)
    
    return line


def is_valid_line(line: str, min_length: int = 5) -> bool:
    """
    æ£€æŸ¥æ–‡æœ¬è¡Œæ˜¯å¦æœ‰æ•ˆ
    
    Args:
        line: æ–‡æœ¬è¡Œ
        min_length: æœ€å°é•¿åº¦
    
    Returns:
        æ˜¯å¦æœ‰æ•ˆ
    """
    if not line or len(line) < min_length:
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆå­—ç¬¦ï¼ˆä¸­æ–‡ã€è‹±æ–‡æˆ–æ•°å­—ï¼‰
    if not re.search(r'[\u4e00-\u9fa5a-zA-Z0-9]', line):
        return False
    
    return True


def preprocess_corpus(input_file: str, output_file: str, min_length: int = 5):
    """
    é¢„å¤„ç†è¯­æ–™æ–‡ä»¶
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        min_length: æœ€å°è¡Œé•¿åº¦
    """
    if not os.path.exists(input_file):
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
    
    print(f"ğŸ“– è¯»å–è¾“å…¥æ–‡ä»¶: {input_file}")
    
    # è·å–æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(input_file)
    file_size_mb = file_size / (1024 * 1024)
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_file)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # å¤„ç†æ–‡ä»¶
    print("ğŸ§¹ é¢„å¤„ç†æ–‡æœ¬...")
    
    valid_lines = 0
    invalid_lines = 0
    
    with open(input_file, 'r', encoding='utf-8', errors='ignore') as f_in:
        with open(output_file, 'w', encoding='utf-8') as f_out:
            # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
            for line in tqdm(f_in, desc="å¤„ç†è¿›åº¦"):
                # é¢„å¤„ç†
                line = preprocess_line(line)
                
                # æ£€æŸ¥æœ‰æ•ˆæ€§
                if is_valid_line(line, min_length=min_length):
                    f_out.write(line + '\n')
                    valid_lines += 1
                else:
                    invalid_lines += 1
    
    print(f"âœ… æœ‰æ•ˆè¡Œæ•°: {valid_lines:,}")
    print(f"âŒ æ— æ•ˆè¡Œæ•°: {invalid_lines:,}")
    print(f"ğŸ“‰ è¿‡æ»¤ç‡: {invalid_lines / (valid_lines + invalid_lines) * 100:.2f}%")
    
    output_size = os.path.getsize(output_file)
    output_size_mb = output_size / (1024 * 1024)
    print(f"âœ… è¾“å‡ºæ–‡ä»¶å¤§å°: {output_size_mb:.2f} MB")
    
    print("ğŸ‰ é¢„å¤„ç†å®Œæˆï¼")


def main():
    parser = argparse.ArgumentParser(
        description="ä¿®å¤ Tokenizer è®­ç»ƒé”™è¯¯ - é¢„å¤„ç†è¯­æ–™æ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # é¢„å¤„ç† wiki.simple.txt
  python fix_tokenizer_training.py \\
    --input ../data/wiki.simple.txt \\
    --output ../data/wiki_clean.txt
  
  # ç„¶åè®­ç»ƒ tokenizer
  python train_tokenizer.py \\
    --method t5-base \\
    --wiki-file ../data/wiki_clean.txt \\
    --output-dir ../model_save/my_tokenizer_wiki \\
    --vocab-size 40960 \\
    --batch-size 500
        """
    )
    
    parser.add_argument(
        '--input', '-i',
        type=str,
        required=True,
        help='è¾“å…¥æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        required=True,
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--min-length',
        type=int,
        default=5,
        help='æœ€å°è¡Œé•¿åº¦ï¼ˆé»˜è®¤ï¼š5ï¼‰'
    )
    
    args = parser.parse_args()
    
    # æ‰§è¡Œé¢„å¤„ç†
    preprocess_corpus(
        input_file=args.input,
        output_file=args.output,
        min_length=args.min_length
    )


if __name__ == '__main__':
    main()
