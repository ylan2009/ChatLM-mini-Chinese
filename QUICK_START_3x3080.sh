#!/bin/bash
# 快速启动命令 - 3×RTX 3080 20GB

# ============================================================================
# 方式1: 最简单（推荐新手）
# ============================================================================
bash run_llamafactory_3x3080.sh


# ============================================================================
# 方式2: 命令行 - llamafactory-cli（推荐）
# ============================================================================
export CUDA_VISIBLE_DEVICES=0,1,2
llamafactory-cli train llamafactory_config_3x3080.yaml


# ============================================================================
# 方式3: 命令行 - deepspeed（最优显存，强烈推荐！）
# ============================================================================
export CUDA_VISIBLE_DEVICES=0,1,2
deepspeed --num_gpus=3 -m llmtuner.cli train llamafactory_config_3x3080.yaml


# ============================================================================
# 方式4: 命令行 - accelerate
# ============================================================================
export CUDA_VISIBLE_DEVICES=0,1,2
accelerate launch --multi_gpu --num_processes=3 -m llmtuner.cli train llamafactory_config_3x3080.yaml


# ============================================================================
# 方式5: 命令行 - torchrun
# ============================================================================
export CUDA_VISIBLE_DEVICES=0,1,2
torchrun --nproc_per_node=3 -m llmtuner.cli train llamafactory_config_3x3080.yaml


# ============================================================================
# 监控训练
# ============================================================================
# 查看GPU使用
watch -n 1 nvidia-smi

# 查看训练日志
tensorboard --logdir=./logs/llamafactory_3x3080


# ============================================================================
# 如果显存不足，修改配置文件中的以下参数：
# ============================================================================
# per_device_train_batch_size: 4  # 8 -> 4
# gradient_accumulation_steps: 32  # 16 -> 32
# cutoff_len: 256  # 512 -> 256


# ============================================================================
# 如果内存不足，修改配置文件中的以下参数：
# ============================================================================
# preprocessing_num_workers: 1  # 2 -> 1
# max_samples: 1000000  # 限制样本数
