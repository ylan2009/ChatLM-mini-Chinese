# ðŸš¨ æ•°æ®é›†åˆ—åä¸åŒ¹é…é”™è¯¯ä¿®å¤

## âŒ é”™è¯¯ä¿¡æ¯

```python
KeyError: 'input'

File "/home/rongtw/anaconda3/envs/chatlm/lib/python3.10/site-packages/llmtuner/data/aligner.py", line 34, in convert_alpaca
    for i in range(len(examples[dataset_attr.prompt])):
KeyError: 'input'
```

---

## ðŸ” é—®é¢˜åˆ†æž

### é”™è¯¯åŽŸå› 

**æ•°æ®é›†åˆ—åä¸åŒ¹é…ï¼**

LLaMA-Factory æ ¹æ® `dataset_info.json` çš„é…ç½®åŽ»æŸ¥æ‰¾åˆ—åï¼Œä½†æ˜¯ parquet æ–‡ä»¶ä¸­æ²¡æœ‰å¯¹åº”çš„åˆ—ï¼

### å½“å‰é…ç½®

```json
// dataset_info.json
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "columns": {
      "prompt": "input",    â† LLaMA-Factory åŽ»æ‰¾ "input" åˆ—
      "response": "target"  â† LLaMA-Factory åŽ»æ‰¾ "target" åˆ—
    }
  }
}
```

### é—®é¢˜

**parquet æ–‡ä»¶ä¸­å¯èƒ½æ²¡æœ‰ "input" å’Œ "target" åˆ—ï¼**

å¯èƒ½çš„æƒ…å†µï¼š
1. åˆ—åä¸æ˜¯ "input" å’Œ "target"
2. åˆ—åå¤§å°å†™ä¸åŒï¼ˆä¾‹å¦‚ "Input" vs "input"ï¼‰
3. åˆ—åæ˜¯å…¶ä»–åç§°ï¼ˆä¾‹å¦‚ "text", "prompt", "question" ç­‰ï¼‰

---

## ðŸ”§ è§£å†³æ­¥éª¤

### æ­¥éª¤1: æ£€æŸ¥ parquet æ–‡ä»¶çš„å®žé™…åˆ—å

**åœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œï¼š**

```bash
cd /data3/ChatLM-mini-Chinese

# è¿è¡Œæ£€æŸ¥è„šæœ¬
python check_parquet_columns.py data/my_train_dataset.parquet
```

**è¿™ä¸ªè„šæœ¬ä¼šæ˜¾ç¤ºï¼š**
- âœ… æ–‡ä»¶çš„æ‰€æœ‰åˆ—å
- âœ… æ¯åˆ—çš„æ•°æ®ç±»åž‹
- âœ… å‰3è¡Œç¤ºä¾‹æ•°æ®
- âœ… ç©ºå€¼ç»Ÿè®¡
- âœ… è‡ªåŠ¨ç”Ÿæˆæ­£ç¡®çš„ dataset_info.json é…ç½®

---

### æ­¥éª¤2: æ ¹æ®å®žé™…åˆ—åä¿®æ”¹ dataset_info.json

#### æƒ…å†µ1: åˆ—åæ˜¯ "text" å’Œ "summary"

å¦‚æžœ parquet æ–‡ä»¶çš„åˆ—åæ˜¯ï¼š
```
text, summary
```

åˆ™ä¿®æ”¹ `dataset_info.json` ä¸ºï¼š

```json
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "text",      â† æ”¹ä¸ºå®žé™…çš„åˆ—å
      "response": "summary"  â† æ”¹ä¸ºå®žé™…çš„åˆ—å
    }
  }
}
```

---

#### æƒ…å†µ2: åˆ—åæ˜¯ "question" å’Œ "answer"

å¦‚æžœ parquet æ–‡ä»¶çš„åˆ—åæ˜¯ï¼š
```
question, answer
```

åˆ™ä¿®æ”¹ `dataset_info.json` ä¸ºï¼š

```json
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "question",  â† æ”¹ä¸ºå®žé™…çš„åˆ—å
      "response": "answer"   â† æ”¹ä¸ºå®žé™…çš„åˆ—å
    }
  }
}
```

---

#### æƒ…å†µ3: åˆ—åå°±æ˜¯ "input" å’Œ "target"ï¼ˆä½†å¤§å°å†™ä¸åŒï¼‰

å¦‚æžœ parquet æ–‡ä»¶çš„åˆ—åæ˜¯ï¼š
```
Input, Target  ï¼ˆæ³¨æ„å¤§å†™ï¼‰
```

åˆ™ä¿®æ”¹ `dataset_info.json` ä¸ºï¼š

```json
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "Input",   â† æ³¨æ„å¤§å°å†™
      "response": "Target" â† æ³¨æ„å¤§å°å†™
    }
  }
}
```

---

#### æƒ…å†µ4: åªæœ‰ä¸€åˆ—ï¼ˆçº¯æ–‡æœ¬é¢„è®­ç»ƒï¼‰

å¦‚æžœ parquet æ–‡ä»¶åªæœ‰ä¸€åˆ—ï¼š
```
text
```

åˆ™ä¿®æ”¹ `dataset_info.json` ä¸ºï¼š

```json
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "text"  â† åªæŒ‡å®š promptï¼Œä¸æŒ‡å®š response
    }
  }
}
```

**å¹¶ä¸”ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š**

```yaml
# llamafactory_config_3x3080.yaml
stage: pt  # é¢„è®­ç»ƒæ¨¡å¼
template: default
```

---

### æ­¥éª¤3: é‡æ–°è¿è¡Œè®­ç»ƒ

```bash
cd /data3/ChatLM-mini-Chinese

# é‡æ–°è¿è¡Œ
bash run_llamafactory_3x3080.sh

# é€‰æ‹©æ–¹å¼ 3
```

---

## ðŸ“Š LLaMA-Factory åˆ—åæ˜ å°„è§„åˆ™

### columns é…ç½®è¯´æ˜Ž

```json
{
  "columns": {
    "prompt": "å®žé™…åˆ—å1",    â† LLaMA-Factory çš„å­—æ®µå â†’ parquet çš„å®žé™…åˆ—å
    "response": "å®žé™…åˆ—å2",  â† LLaMA-Factory çš„å­—æ®µå â†’ parquet çš„å®žé™…åˆ—å
    "query": "å®žé™…åˆ—å3",     â† å¯é€‰ï¼šå¯¹è¯åŽ†å²
    "history": "å®žé™…åˆ—å4"    â† å¯é€‰ï¼šå¤šè½®å¯¹è¯
  }
}
```

### LLaMA-Factory æ”¯æŒçš„å­—æ®µ

| LLaMA-Factory å­—æ®µ | è¯´æ˜Ž | å¿…éœ€ | ç¤ºä¾‹ |
|-------------------|------|------|------|
| `prompt` | è¾“å…¥æ–‡æœ¬/é—®é¢˜ | âœ… æ˜¯ | "è¯·ä»‹ç»ä¸€ä¸‹åŒ—äº¬" |
| `response` | è¾“å‡ºæ–‡æœ¬/ç­”æ¡ˆ | âš ï¸ ç›‘ç£å­¦ä¹ å¿…éœ€ | "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½..." |
| `query` | å½“å‰é—®é¢˜ | âŒ å¦ | "å¤©æ°”æ€Žä¹ˆæ ·ï¼Ÿ" |
| `history` | å¯¹è¯åŽ†å² | âŒ å¦ | [["ä½ å¥½", "ä½ å¥½ï¼"]] |
| `system` | ç³»ç»Ÿæç¤º | âŒ å¦ | "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹" |

### ä¸åŒè®­ç»ƒé˜¶æ®µçš„è¦æ±‚

| è®­ç»ƒé˜¶æ®µ | stage | å¿…éœ€å­—æ®µ | è¯´æ˜Ž |
|---------|-------|---------|------|
| é¢„è®­ç»ƒ | `pt` | `prompt` | åªéœ€è¦æ–‡æœ¬ï¼Œä¸éœ€è¦ response |
| ç›‘ç£å¾®è°ƒ | `sft` | `prompt`, `response` | éœ€è¦è¾“å…¥å’Œè¾“å‡º |
| å¥–åŠ±æ¨¡åž‹ | `rm` | `prompt`, `response` | éœ€è¦è¾“å…¥å’Œè¾“å‡º |
| å¼ºåŒ–å­¦ä¹  | `ppo` | `prompt` | åªéœ€è¦è¾“å…¥ |

---

## ðŸ” å¸¸è§åˆ—åå¯¹åº”å…³ç³»

### å¸¸è§çš„è¾“å…¥åˆ—å

| å®žé™…åˆ—å | å¯¹åº”é…ç½® |
|---------|---------|
| `input` | `"prompt": "input"` |
| `text` | `"prompt": "text"` |
| `prompt` | `"prompt": "prompt"` |
| `question` | `"prompt": "question"` |
| `instruction` | `"prompt": "instruction"` |
| `query` | `"prompt": "query"` |
| `content` | `"prompt": "content"` |

### å¸¸è§çš„è¾“å‡ºåˆ—å

| å®žé™…åˆ—å | å¯¹åº”é…ç½® |
|---------|---------|
| `target` | `"response": "target"` |
| `output` | `"response": "output"` |
| `response` | `"response": "response"` |
| `answer` | `"response": "answer"` |
| `completion` | `"response": "completion"` |
| `summary` | `"response": "summary"` |
| `label` | `"response": "label"` |

---

## ðŸ› ï¸ æ‰‹åŠ¨æ£€æŸ¥ parquet æ–‡ä»¶

### æ–¹æ³•1: ä½¿ç”¨ Python

```bash
cd /data3/ChatLM-mini-Chinese

python -c "
import pandas as pd

# è¯»å–æ–‡ä»¶
df = pd.read_parquet('data/my_train_dataset.parquet')

# æ˜¾ç¤ºåˆ—å
print('åˆ—å:', df.columns.tolist())

# æ˜¾ç¤ºå‰3è¡Œ
print('\nå‰3è¡Œ:')
print(df.head(3))
"
```

---

### æ–¹æ³•2: ä½¿ç”¨ check_parquet_columns.pyï¼ˆæŽ¨èï¼‰

```bash
cd /data3/ChatLM-mini-Chinese

# è¿è¡Œæ£€æŸ¥è„šæœ¬
python check_parquet_columns.py data/my_train_dataset.parquet
```

**è¾“å‡ºç¤ºä¾‹ï¼š**

```
æ­£åœ¨æ£€æŸ¥æ–‡ä»¶: data/my_train_dataset.parquet
================================================================================

âœ“ æ–‡ä»¶è¯»å–æˆåŠŸï¼
  æ€»è¡Œæ•°: 8,813,083
  æ€»åˆ—æ•°: 2

ðŸ“‹ åˆ—ååˆ—è¡¨:
  1. text
  2. summary

ðŸ“Š æ•°æ®ç±»åž‹:
  text: object
  summary: object

ðŸ“ å‰3è¡Œæ•°æ®:

ç¬¬ 1 è¡Œ:
  text: è¿™æ˜¯ä¸€æ®µè¾“å…¥æ–‡æœ¬...
  summary: è¿™æ˜¯å¯¹åº”çš„æ‘˜è¦...

...

ðŸ’¡ dataset_info.json é…ç½®å»ºè®®:
--------------------------------------------------------------------------------

{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "text",
      "response": "summary"
    }
  }
}

âœ“ è‡ªåŠ¨è¯†åˆ«åˆ°:
  - prompt åˆ—: text
  - response åˆ—: summary
================================================================================
```

---

## ðŸ“ ä¿®å¤ç¤ºä¾‹

### ç¤ºä¾‹1: åˆ—åæ˜¯ "text" å’Œ "summary"

#### æ£€æŸ¥ç»“æžœ

```bash
$ python check_parquet_columns.py data/my_train_dataset.parquet

åˆ—å: ['text', 'summary']
```

#### ä¿®å¤ dataset_info.json

```json
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "text",      â† æ”¹ä¸º "text"
      "response": "summary"  â† æ”¹ä¸º "summary"
    }
  }
}
```

#### ä¿®å¤å‘½ä»¤

```bash
cd /data3/ChatLM-mini-Chinese

# å¤‡ä»½åŽŸæ–‡ä»¶
cp dataset_info.json dataset_info.json.bak

# ä¿®æ”¹æ–‡ä»¶
cat > dataset_info.json << 'EOF'
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "text",
      "response": "summary"
    }
  }
}
EOF

# éªŒè¯
cat dataset_info.json
```

---

### ç¤ºä¾‹2: åªæœ‰ä¸€åˆ— "text"ï¼ˆé¢„è®­ç»ƒï¼‰

#### æ£€æŸ¥ç»“æžœ

```bash
$ python check_parquet_columns.py data/my_train_dataset.parquet

åˆ—å: ['text']
```

#### ä¿®å¤ dataset_info.json

```json
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "text"  â† åªæœ‰ä¸€åˆ—
    }
  }
}
```

#### ä¿®å¤å‘½ä»¤

```bash
cd /data3/ChatLM-mini-Chinese

# ä¿®æ”¹ dataset_info.json
cat > dataset_info.json << 'EOF'
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "text"
    }
  }
}
EOF

# ç¡®è®¤é…ç½®æ–‡ä»¶æ˜¯é¢„è®­ç»ƒæ¨¡å¼
grep "stage:" llamafactory_config_3x3080.yaml
# åº”è¯¥è¾“å‡º: stage: pt
```

---

## ðŸŽ¯ å¿«é€Ÿä¿®å¤æµç¨‹

### 1ï¸âƒ£ æ£€æŸ¥åˆ—å

```bash
cd /data3/ChatLM-mini-Chinese
python check_parquet_columns.py data/my_train_dataset.parquet
```

### 2ï¸âƒ£ è®°å½•å®žé™…åˆ—å

å‡è®¾è¾“å‡ºæ˜¯ï¼š
```
åˆ—å: ['text', 'summary']
```

### 3ï¸âƒ£ ä¿®æ”¹ dataset_info.json

```bash
cat > dataset_info.json << 'EOF'
{
  "custom_t5_dataset": {
    "file_name": "data/my_train_dataset.parquet",
    "file_format": "parquet",
    "columns": {
      "prompt": "text",
      "response": "summary"
    }
  }
}
EOF
```

### 4ï¸âƒ£ éªŒè¯ä¿®æ”¹

```bash
cat dataset_info.json
```

### 5ï¸âƒ£ é‡æ–°è¿è¡Œè®­ç»ƒ

```bash
bash run_llamafactory_3x3080.sh
# é€‰æ‹©æ–¹å¼ 3
```

---

## ðŸ’¡ æ·±å…¥ç†è§£

### LLaMA-Factory æ•°æ®åŠ è½½æµç¨‹

```python
# 1. è¯»å– dataset_info.json
dataset_info = {
    "custom_t5_dataset": {
        "columns": {
            "prompt": "input",    # LLaMA-Factory å­—æ®µ â†’ parquet åˆ—å
            "response": "target"
        }
    }
}

# 2. åŠ è½½ parquet æ–‡ä»¶
df = pd.read_parquet("data/my_train_dataset.parquet")
# df.columns = ['text', 'summary']  â† å®žé™…åˆ—å

# 3. å°è¯•è®¿é—®åˆ—ï¼ˆè¿™é‡Œä¼šå‡ºé”™ï¼ï¼‰
prompt_column = dataset_info["columns"]["prompt"]  # "input"
examples[prompt_column]  # å°è¯•è®¿é—® examples["input"]
# âŒ KeyError: 'input'  å› ä¸ºå®žé™…åˆ—åæ˜¯ 'text'ï¼Œä¸æ˜¯ 'input'

# 4. æ­£ç¡®çš„é…ç½®åº”è¯¥æ˜¯
dataset_info = {
    "custom_t5_dataset": {
        "columns": {
            "prompt": "text",     # âœ… ä½¿ç”¨å®žé™…åˆ—å
            "response": "summary"
        }
    }
}
```

### åˆ—åæ˜ å°„åŽŸç†

```
LLaMA-Factory å†…éƒ¨å­—æ®µ â†’ dataset_info.json æ˜ å°„ â†’ parquet å®žé™…åˆ—å

prompt                  â†’ "prompt": "text"      â†’ df["text"]
response                â†’ "response": "summary" â†’ df["summary"]
```

**å…³é”®ç‚¹ï¼š**
- `"prompt": "text"` è¡¨ç¤ºï¼šLLaMA-Factory çš„ `prompt` å­—æ®µå¯¹åº” parquet çš„ `text` åˆ—
- `"response": "summary"` è¡¨ç¤ºï¼šLLaMA-Factory çš„ `response` å­—æ®µå¯¹åº” parquet çš„ `summary` åˆ—

---

## ðŸ” è°ƒè¯•æŠ€å·§

### 1. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯

```bash
# è¿è¡Œæ—¶æ·»åŠ è°ƒè¯•ä¿¡æ¯
export PYTHONPATH=/data3/ChatLM-mini-Chinese:$PYTHONPATH
export DATASETS_VERBOSITY=debug

bash run_llamafactory_3x3080.sh
```

### 2. æµ‹è¯•æ•°æ®åŠ è½½

```bash
cd /data3/ChatLM-mini-Chinese

python -c "
import json
import pandas as pd

# è¯»å–é…ç½®
with open('dataset_info.json') as f:
    config = json.load(f)

dataset_config = config['custom_t5_dataset']
file_name = dataset_config['file_name']
columns = dataset_config['columns']

print(f'é…ç½®çš„åˆ—åæ˜ å°„:')
for k, v in columns.items():
    print(f'  {k} â†’ {v}')

# è¯»å–æ•°æ®
df = pd.read_parquet(file_name)
print(f'\nå®žé™…çš„åˆ—å:')
for col in df.columns:
    print(f'  {col}')

# æ£€æŸ¥æ˜ å°„æ˜¯å¦æ­£ç¡®
print(f'\næ˜ å°„æ£€æŸ¥:')
for k, v in columns.items():
    if v in df.columns:
        print(f'  âœ“ {k} â†’ {v} (å­˜åœ¨)')
    else:
        print(f'  âœ— {k} â†’ {v} (ä¸å­˜åœ¨ï¼)')
        print(f'    å¯ç”¨åˆ—å: {list(df.columns)}')
"
```

---

## ðŸ“š ç›¸å…³æ–‡æ¡£

- [check_parquet_columns.py](check_parquet_columns.py) - åˆ—åæ£€æŸ¥è„šæœ¬
- [FIX_DATASET_PATH.md](FIX_DATASET_PATH.md) - æ•°æ®é›†è·¯å¾„é”™è¯¯
- [FIX_NCCL_SHM_ERROR.md](FIX_NCCL_SHM_ERROR.md) - NCCL é”™è¯¯
- [llamafactory_config_3x3080.yaml](llamafactory_config_3x3080.yaml) - è®­ç»ƒé…ç½®

---

## ðŸŽ‰ æ€»ç»“

**é—®é¢˜ï¼š** LLaMA-Factory æ‰¾ä¸åˆ° "input" åˆ—

**åŽŸå› ï¼š** dataset_info.json é…ç½®çš„åˆ—åä¸Ž parquet æ–‡ä»¶å®žé™…åˆ—åä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆï¼š**
1. è¿è¡Œ `python check_parquet_columns.py data/my_train_dataset.parquet`
2. æŸ¥çœ‹å®žé™…åˆ—å
3. ä¿®æ”¹ `dataset_info.json` ä¸­çš„ `columns` é…ç½®
4. é‡æ–°è¿è¡Œè®­ç»ƒ

**å…³é”®å‘½ä»¤ï¼š**
```bash
cd /data3/ChatLM-mini-Chinese
python check_parquet_columns.py data/my_train_dataset.parquet
# æ ¹æ®è¾“å‡ºä¿®æ”¹ dataset_info.json
bash run_llamafactory_3x3080.sh
```
