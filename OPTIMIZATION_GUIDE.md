# å¤§æ•°æ®é›†é¢„è®­ç»ƒä¼˜åŒ–æŒ‡å—

## ğŸ¯ ç¡¬ä»¶ç¯å¢ƒ

- **GPU**: 3å¼  NVIDIA 3080 (20GBæ˜¾å­˜/å¼ )
- **å†…å­˜**: 12GB
- **æ•°æ®é‡**: 1000ä¸‡è®­ç»ƒæ ·æœ¬

## ğŸ“Š ä¼˜åŒ–ç­–ç•¥æ€»ç»“

### 1. é…ç½®é€‰æ‹©ï¼šTrainConfigPretrainLarge

é’ˆå¯¹ä½ çš„ç¡¬ä»¶ç¯å¢ƒï¼Œæˆ‘åˆ›å»ºäº†ä¸“é—¨çš„é…ç½®ç±» `TrainConfigPretrainLarge`ï¼Œä¸»è¦ä¼˜åŒ–ç‚¹ï¼š

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `batch_size_per_gpu` | 32 | å……åˆ†åˆ©ç”¨20Gæ˜¾å­˜ |
| `gradient_accumulation_steps` | 2 | é™ä½å†…å­˜å ç”¨ |
| `max_seq_len` | 192 | é¢„è®­ç»ƒé˜¶æ®µè¶³å¤Ÿï¼Œé™ä½æ˜¾å­˜å ç”¨ |
| `dataloader_buffer_size` | 5000 | å‡å°bufferï¼Œé™ä½å†…å­˜å ç”¨ |
| `epochs` | 3 | å¤§æ•°æ®é›†3ä¸ªepochè¶³å¤Ÿ |
| `save_steps` | 5000 | æ¯5000æ­¥ä¿å­˜ä¸€æ¬¡ |
| `logging_steps` | 100 | æ¯100æ­¥è®°å½•ä¸€æ¬¡ |

**å®é™…æœ‰æ•ˆbatch_size** = 32 Ã— 3(GPU) Ã— 2(æ¢¯åº¦ç´¯ç§¯) = **192**

### 2. å†…å­˜ä¼˜åŒ–ç­–ç•¥

#### 2.1 æ•°æ®åŠ è½½ä¼˜åŒ–
- âœ… **ultra_low_memæ¨¡å¼**: å¯ç”¨ï¼ˆ12Gå†…å­˜<15GBé˜ˆå€¼ï¼‰
  - æ¯æ¬¡è¯»å–æ—¶é‡æ–°æ‰“å¼€parquetæ–‡ä»¶
  - é¿å…PyArrowç¼“å­˜ç´¯ç§¯
  - ç¨å¾®é™ä½é€Ÿåº¦ï¼Œä½†æ˜¾è‘—å‡å°‘å†…å­˜å ç”¨

- âœ… **num_workers**: ç¦ç”¨ï¼ˆè®¾ä¸º0ï¼‰
  - é¿å…å¤šè¿›ç¨‹å†…å­˜å¼€é”€
  - 12Gå†…å­˜ç¯å¢ƒä¸‹å¿…é¡»ç¦ç”¨

- âœ… **pin_memory**: ç¦ç”¨
  - é¿å…é¢å¤–å†…å­˜å ç”¨
  - ä»…åœ¨å†…å­˜>15GBæ—¶å¯ç”¨

#### 2.2 è®­ç»ƒä¼˜åŒ–
- âœ… **æ¢¯åº¦ç´¯ç§¯**: 2æ­¥ï¼ˆé…ç½®å€¼ï¼‰
  - 12Gå†…å­˜ + 3GPUç¯å¢ƒä½¿ç”¨é…ç½®å€¼
  - é™ä½å†…å­˜å ç”¨ï¼ŒåŒæ—¶ä¿æŒå¤§batch_sizeæ•ˆæœ

- âœ… **æ··åˆç²¾åº¦**: bf16
  - é™ä½æ˜¾å­˜å ç”¨
  - æå‡è®­ç»ƒé€Ÿåº¦

- âœ… **å®šæœŸæ¸…ç†å†…å­˜**:
  - æ¯50æ­¥æ¸…ç†ä¸€æ¬¡GPUå’ŒCPUç¼“å­˜
  - æ¯200æ­¥å¼ºåˆ¶æ¸…ç†å¹¶è®°å½•å†…å­˜ä½¿ç”¨

### 3. æ˜¾å­˜ä¼˜åŒ–ç­–ç•¥

#### 3.1 åºåˆ—é•¿åº¦ä¼˜åŒ–
- **max_seq_len**: 192ï¼ˆè€Œé512ï¼‰
  - é¢„è®­ç»ƒé˜¶æ®µ192è¶³å¤Ÿå­¦ä¹ è¯­è¨€æ¨¡å¼
  - æ˜¾å­˜å ç”¨é™ä½çº¦60%ï¼ˆåºåˆ—é•¿åº¦çš„å¹³æ–¹å…³ç³»ï¼‰
  - è®­ç»ƒé€Ÿåº¦æå‡çº¦2.7å€

#### 3.2 Batch Sizeä¼˜åŒ–
- **batch_size_per_gpu**: 32
  - å……åˆ†åˆ©ç”¨20Gæ˜¾å­˜
  - é¢„è®¡æ˜¾å­˜å ç”¨ï¼š16-18GB/GPU
  - ç•™æœ‰2-4GBä½™é‡ï¼Œé¿å…OOM

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ­¥éª¤1: å‡†å¤‡æ•°æ®

ç¡®ä¿ä½ çš„æ•°æ®æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼ˆåœ¨ `config.py` ä¸­é…ç½®ï¼‰ï¼š

```python
# TrainConfigPretrainLarge é…ç½®
train_file: str = PROJECT_ROOT + '/data/pretrain_train_10m.parquet'      # 1000ä¸‡è®­ç»ƒæ•°æ®
validation_file: str = PROJECT_ROOT + '/data/pretrain_valid_100k.parquet'  # 10ä¸‡éªŒè¯æ•°æ®
```

æ•°æ®æ ¼å¼è¦æ±‚ï¼ˆparquetæ–‡ä»¶ï¼‰ï¼š
- åˆ—åï¼š`prompt`, `response`
- æ¯è¡Œä¸€ä¸ªæ ·æœ¬

### æ­¥éª¤2: å¯åŠ¨è®­ç»ƒ

```bash
# ä½¿ç”¨3å¼ GPUè¿›è¡Œå¤§æ•°æ®é›†é¢„è®­ç»ƒ
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True

# ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --is_keep_training=True

# è‡ªå®šä¹‰å‚æ•°ï¼ˆè¦†ç›–é…ç½®ï¼‰
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --epochs=5 --learn_rate=0.0002
```

### æ­¥éª¤3: ç›‘æ§è®­ç»ƒ

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨è®°å½•ï¼š
- âœ… å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆæ¯200æ­¥ï¼‰
- âœ… GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ
- âœ… è®­ç»ƒlossï¼ˆæ¯100æ­¥ï¼‰
- âœ… éªŒè¯BLEU4åˆ†æ•°ï¼ˆæ¯ä¸ªepochï¼‰

æ—¥å¿—æ–‡ä»¶ä½ç½®ï¼š
- è®­ç»ƒæ—¥å¿—ï¼š`logs/chat_trainer_low_mem_YYYYMMDD.log`
- æ¨¡å‹ä¿å­˜ï¼š`model_save/pretrain_large/`

## ğŸ“ˆ é¢„æœŸæ€§èƒ½

### è®­ç»ƒé€Ÿåº¦
- **æ¯ä¸ªepochæ­¥æ•°**: çº¦52,083æ­¥
  - è®¡ç®—ï¼š10,000,000 / (32 Ã— 3 Ã— 2) â‰ˆ 52,083
- **æ¯æ­¥è€—æ—¶**: çº¦0.5-0.8ç§’ï¼ˆå–å†³äºCPUæ€§èƒ½ï¼‰
- **æ¯ä¸ªepochè€—æ—¶**: çº¦7-11å°æ—¶
- **3ä¸ªepochæ€»è€—æ—¶**: çº¦21-33å°æ—¶

### èµ„æºå ç”¨
- **å†…å­˜å ç”¨**: 8-10GBï¼ˆå³°å€¼ï¼‰
- **GPUæ˜¾å­˜å ç”¨**: 16-18GB/GPU
- **ç£ç›˜å ç”¨**: 
  - æ¯ä¸ªcheckpoint: çº¦0.7-0.8GB
  - ä¿ç•™5ä¸ªæœ€å¥½çš„æ¨¡å‹: çº¦3.5-4GB
  - è®­ç»ƒçŠ¶æ€: çº¦1-2GB

### è®­ç»ƒæ•ˆæœ
- **å®é™…batch_size**: 192ï¼ˆå¤§batchæå‡è®­ç»ƒç¨³å®šæ€§ï¼‰
- **åºåˆ—é•¿åº¦**: 192ï¼ˆé¢„è®­ç»ƒé˜¶æ®µè¶³å¤Ÿï¼‰
- **å­¦ä¹ ç‡**: 0.0001ï¼ˆæ ‡å‡†å­¦ä¹ ç‡ï¼‰
- **warmupæ­¥æ•°**: 1024æ­¥

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. å†…å­˜ä¸è¶³å¤„ç†

å¦‚æœè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°å†…å­˜ä¸è¶³ï¼ˆOOMï¼‰ï¼Œå¯ä»¥å°è¯•ï¼š

#### æ–¹æ¡ˆA: å‡å°batch_size
```bash
# å°†batch_sizeä»32é™åˆ°24
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --batch_size_per_gpu=24
```

#### æ–¹æ¡ˆB: å¢åŠ æ¢¯åº¦ç´¯ç§¯
```bash
# å°†æ¢¯åº¦ç´¯ç§¯ä»2å¢åˆ°4ï¼ŒåŒæ—¶å‡å°batch_size
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --batch_size_per_gpu=16 --gradient_accumulation_steps=4
```

#### æ–¹æ¡ˆC: è¿›ä¸€æ­¥ç¼©çŸ­åºåˆ—é•¿åº¦
```bash
# å°†åºåˆ—é•¿åº¦ä»192é™åˆ°128
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --max_seq_len=128
```

### 2. æ˜¾å­˜ä¸è¶³å¤„ç†

å¦‚æœGPUæ˜¾å­˜ä¸è¶³ï¼ˆCUDA OOMï¼‰ï¼Œå¯ä»¥å°è¯•ï¼š

#### æ–¹æ¡ˆA: å‡å°batch_sizeï¼ˆæ¨èï¼‰
```bash
# ä»32é™åˆ°24
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --batch_size_per_gpu=24
```

#### æ–¹æ¡ˆB: ç¼©çŸ­åºåˆ—é•¿åº¦
```bash
# ä»192é™åˆ°128
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --max_seq_len=128
```

### 3. ç£ç›˜ç©ºé—´ç®¡ç†

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨æ¸…ç†æ—§checkpointï¼Œåªä¿ç•™5ä¸ªæœ€å¥½çš„æ¨¡å‹ã€‚å¦‚æœç£ç›˜ç©ºé—´ä¸è¶³ï¼š

```python
# åœ¨ config.py ä¸­ä¿®æ”¹
keep_latest_n_ckp: int = 3  # ä»5æ”¹ä¸º3
```

### 4. NCCLå…±äº«å†…å­˜é—®é¢˜

å¦‚æœé‡åˆ°NCCLåˆå§‹åŒ–é”™è¯¯ï¼Œå·²åœ¨ `train_low_mem.py` ä¸­é…ç½®ï¼š

```python
os.environ.setdefault('NCCL_SHM_DISABLE', '0')  # å¯ç”¨å…±äº«å†…å­˜
os.environ.setdefault('NCCL_TIMEOUT', '1800')   # 30åˆ†é’Ÿè¶…æ—¶
```

å¦‚æœä»æœ‰é—®é¢˜ï¼Œå¯ä»¥å°è¯•ç¦ç”¨å…±äº«å†…å­˜ï¼š
```python
os.environ.setdefault('NCCL_SHM_DISABLE', '1')  # ç¦ç”¨å…±äº«å†…å­˜
```

## ğŸ”§ å‚æ•°è°ƒä¼˜å»ºè®®

### 1. å­¦ä¹ ç‡è°ƒä¼˜

å¦‚æœè®­ç»ƒlossä¸ä¸‹é™æˆ–æ³¢åŠ¨å¤§ï¼š

```bash
# é™ä½å­¦ä¹ ç‡
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --learn_rate=5e-5

# æˆ–å¢åŠ warmupæ­¥æ•°
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --warmup_steps=2048
```

### 2. è®­ç»ƒè½®æ•°è°ƒä¼˜

å¤§æ•°æ®é›†é€šå¸¸3ä¸ªepochè¶³å¤Ÿï¼Œå¦‚æœéœ€è¦æ›´å¤šï¼š

```bash
# å¢åŠ åˆ°5ä¸ªepoch
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --epochs=5
```

### 3. ä¿å­˜é¢‘ç‡è°ƒä¼˜

å¦‚æœæƒ³æ›´é¢‘ç¹åœ°ä¿å­˜æ¨¡å‹ï¼š

```bash
# æ¯2000æ­¥ä¿å­˜ä¸€æ¬¡ï¼ˆåŸæ¥æ˜¯5000æ­¥ï¼‰
accelerate launch --multi_gpu --num_processes 3 ./train_low_mem.py train --use_large_config=True --save_steps=2000
```

## ğŸ“ é…ç½®å¯¹æ¯”

| é…ç½®é¡¹ | TrainConfig (åŸå§‹) | TrainConfigPretrainLarge (ä¼˜åŒ–) | æå‡ |
|--------|-------------------|--------------------------------|------|
| batch_size_per_gpu | 16 | 32 | 2å€ |
| gradient_accumulation | 8 | 2 | é™ä½4å€å†…å­˜ |
| å®é™…batch_size | 16Ã—2Ã—8=256 | 32Ã—3Ã—2=192 | ç›¸å½“ |
| max_seq_len | 256 | 192 | é™ä½25% |
| æ˜¾å­˜å ç”¨ | çº¦12GB | çº¦16GB | å……åˆ†åˆ©ç”¨ |
| å†…å­˜å ç”¨ | çº¦10GB | çº¦8GB | é™ä½20% |
| è®­ç»ƒé€Ÿåº¦ | åŸºå‡† | æå‡çº¦30% | - |

## ğŸ“ æœ€ä½³å®è·µ

1. **é¦–æ¬¡è®­ç»ƒ**: ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œè§‚å¯Ÿèµ„æºå ç”¨
2. **èµ„æºå……è¶³**: å¯ä»¥å¢å¤§batch_sizeæˆ–åºåˆ—é•¿åº¦
3. **èµ„æºä¸è¶³**: æŒ‰ç…§"æ³¨æ„äº‹é¡¹"ä¸­çš„æ–¹æ¡ˆè°ƒæ•´
4. **å®šæœŸç›‘æ§**: æŸ¥çœ‹æ—¥å¿—ä¸­çš„å†…å­˜å’Œæ˜¾å­˜ä½¿ç”¨æƒ…å†µ
5. **æ–­ç‚¹ç»­è®­**: ä½¿ç”¨ `--is_keep_training=True` ä»æ–­ç‚¹ç»§ç»­

## ğŸ“ é—®é¢˜æ’æŸ¥

### é—®é¢˜1: å†…å­˜æº¢å‡ºï¼ˆKilledï¼‰
**åŸå› **: ç³»ç»Ÿå†…å­˜ä¸è¶³  
**è§£å†³**: 
- å‡å°batch_size
- å¢åŠ æ¢¯åº¦ç´¯ç§¯
- ç¡®ä¿ultra_low_memæ¨¡å¼å·²å¯ç”¨

### é—®é¢˜2: GPUæ˜¾å­˜æº¢å‡ºï¼ˆCUDA OOMï¼‰
**åŸå› **: GPUæ˜¾å­˜ä¸è¶³  
**è§£å†³**:
- å‡å°batch_size
- ç¼©çŸ­max_seq_len
- æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºå ç”¨æ˜¾å­˜

### é—®é¢˜3: è®­ç»ƒé€Ÿåº¦æ…¢
**åŸå› **: æ•°æ®åŠ è½½æ…¢æˆ–batch_sizeå¤ªå°  
**è§£å†³**:
- ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨SSDä¸Š
- å¢å¤§batch_sizeï¼ˆå¦‚æœèµ„æºå…è®¸ï¼‰
- æ£€æŸ¥CPUå ç”¨æƒ…å†µ

### é—®é¢˜4: Lossä¸ä¸‹é™
**åŸå› **: å­¦ä¹ ç‡ä¸åˆé€‚æˆ–æ•°æ®é—®é¢˜  
**è§£å†³**:
- è°ƒæ•´å­¦ä¹ ç‡ï¼ˆé™ä½æˆ–å¢åŠ ï¼‰
- å¢åŠ warmupæ­¥æ•°
- æ£€æŸ¥æ•°æ®è´¨é‡

## ğŸ‰ æ€»ç»“

é€šè¿‡ä»¥ä¸Šä¼˜åŒ–ï¼Œä½ çš„è®­ç»ƒç¯å¢ƒåº”è¯¥èƒ½å¤Ÿï¼š
- âœ… åœ¨12Gå†…å­˜ä¸‹ç¨³å®šè¿è¡Œ
- âœ… å……åˆ†åˆ©ç”¨3Ã—20Gæ˜¾å­˜GPU
- âœ… é«˜æ•ˆè®­ç»ƒ1000ä¸‡æ•°æ®
- âœ… æ¯ä¸ªepochçº¦7-11å°æ—¶
- âœ… 3ä¸ªepochæ€»è€—æ—¶çº¦21-33å°æ—¶

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
